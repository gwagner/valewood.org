<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	 xmlns:media="http://search.yahoo.com/mrss/" >

<channel>
	<title>tools &#8211; A DevOps Blog</title>
	<atom:link href="https://www.valewood.org/tag/tools/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.valewood.org/</link>
	<description>Occasionally a developer makes an Ops!</description>
	<lastBuildDate>Sun, 06 Nov 2022 01:21:07 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.0.2</generator>

<image>
	<url>https://www.valewood.org/wp-content/uploads/2022/08/A-DevOoops-1-e1660773390219.png</url>
	<title>tools &#8211; A DevOps Blog</title>
	<link>https://www.valewood.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>What is Automation Testing in DevOps</title>
		<link>https://www.valewood.org/devops-testing/</link>
		
		<dc:creator><![CDATA[Greer Shepherd]]></dc:creator>
		<pubDate>Fri, 28 Oct 2022 19:39:07 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[testing]]></category>
		<category><![CDATA[tools]]></category>
		<guid isPermaLink="false">/?p=1239</guid>

					<description><![CDATA[Automation Testing in DevOps is generally relegated to the software being released to production. Environmental testing is performed by manual testing practices or high-level smoke tests. Test automation should cover the full CI/CD pipeline including infrastructure, delivery tools, software, UI,&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Automation Testing in <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="How To Leverage the DevOps Methodology for Success!​" target="_blank" rel="noopener">DevOps</a> is generally relegated to the software being released to production. Environmental testing is performed by manual testing practices or high-level smoke tests.</p>



<p><strong>Test automation should cover the full CI/CD pipeline including infrastructure, delivery tools, software, UI, and any other technology that is included in the pipeline. Automated tests should not be relegated to the land of software development.</strong></p>



<p>Let&#8217;s explore what automation testing in DevOps really means when you are looking to stabilize your delivery process and accelerate your business!</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Automated Testing in DevOps</h2>



<p>Generally, developers tend toward coding unit tests to validate that the code is running the way they expected. At the same time, quality practitioners create automated user tests that validate the end-to-end user experience.</p>



<p>Quality practitioners can arrange explorative testing sessions in which teams manually look at various application area issues.</p>



<p>DevOps&#8217; best practice for the automation of CI/CD pipelines is to run automatic testing whenever possible. This means deploying automatic test UIs to production to detect and proactively address user experience concerns.</p>



<p>I generally like to take this a step further when looking at environmental conditions. Tests for environments can also be thought about in the context of monitoring and observability. A pipeline should be qualified through the use of testing tools in an automated test process. The tests should also be composed in a way that they are usable as part of your monitoring system.</p>



<p>For example, if you are willing to validate that a certificate is valid as part of your testing framework, you should also be willing to run continuous testing to validate that the certificate does not expire between releases.</p>



<h2>The Importance of Test Automation</h2>



<p>Test automation improves reliability, continuity, and productivity within teams of developers and products. DevOps teams have a better chance of staying within budget without disrupting crucial debugging or problem-shooting processes.</p>



<p>Test automation can be quicker than manual testing. It helps to avoid costly errors by eliminating communication barriers and saves money in teams by eliminating unnecessary work. Testing automation provides new forms of flexibility that enable the development team to reuse test scripts across the testing software.</p>



<p>As a business leader, do not be fooled by the short-term investment cost of introducing automated testing into your environment. Testing automation is not new and sexy functionality that you can provide to the market which is why I believe it is skipped by many businesses. Automated testing, continuous integration, and continuous delivery are critical investments to the longevity of your products.</p>



<p>Each release is always going to end up being more complex than the previous release. Employing a good testing process ensures that your products are being introduced to the market in a reliable and expected way. Because of the increased complexity, any manual testing process will need to scale to meet that complexity. Automated testing does not scale in cost the same way that manual testing does.</p>



<h2>What is test automation?</h2>



<p>Test Automation enables users to automate their software testing to ensure that they meet specified quality standards. Different types of testing are often depicted in pyramids. As you ascend the pyramid, the number of testing types decreases, and the costs of creating and operating the test increase. The most traditional tests were conducted using manual methods in the Pyramids in the past. It was a slow and costly procedure until automated testing tooling came into effect.</p>



<figure class="wp-block-image"><a href="https://www.headspin.io/blog/the-testing-pyramid-simplified-for-one-and-all" target="_blank" rel="noopener"><img src="https://global-uploads.webflow.com/619e15d781b21202de206fb5/6316d9e765cd53d9937e2b6a_The-Testing-Pyramid-Simplified-for-One-and-All.webp" alt="The Testing Pyramid"/></a><figcaption>Headspin: The Testing Pyramid: Simplified for One and All</figcaption></figure>



<h2>Common Test Automation Pitfalls</h2>



<p>Below are some of the most common issues when adding automated testing to your technology products:</p>



<ul><li>Developers not participating in testing</li><li>Unit tests not being written with code</li><li>Testing tools are not being used to their fullest potential</li><li>No standard for code coverage</li><li>Best practices not being employed for a specific technology stack</li><li>Tests are not being run in the proper places of a pipeline.</li></ul>



<h2>How Automated Testing Powers DevOps?</h2>



<p>One of the core goals of DevOps is to improve delivery flow. Test automation is one of the core strategies used to help smooth out both flow and quality expectations. A cultural pillar of DevOps is continuous improvement.</p>



<p>Due to the shortened feedback loop of your continuous delivery pipeline, smaller and more nimble software testing and release cycles can be achieved by the development team. This means that your applications will be less prone to errors due to robust testing.</p>



<p>When issues are discovered in production they are not turned into a grandiose response event. A DevOps team is able to get adjustments made to both code and tests and re-release the software quickly back into production.</p>



<p>Without automating releases and tests, teams will scramble to recertify software before being ready to push it back to production with bug fixes. Worse, if your software teams do not employ any testing, you may never know about critical issues before customers bring them up.</p>



<h2>How Can I Improve Continuous Testing?</h2>



<p>Continuous testing is one of the most important things you can do to improve your success rates. If you’re doing it right, continuous testing will help you catch bugs at the earliest stages of development and make sure that problems don’t creep up in production.</p>



<p>Continuous testing helps to keep projects on track and ensure that they stay on schedule, which means that your customers get their products sooner.</p>



<p>A good way to start building a continuous test strategy is by creating an automated integration test pipeline. It should consist of a series of tests that are run automatically when new code is added to your application.</p>



<p>Automated integration tests can be especially useful when you have a large team developing multiple applications that share common code libraries or frameworks. They can also be useful for large-scale applications with many users and complex data models.</p>



<p>Continuous testing also allows developers to build trust with their customers by letting them know that their products are being continuously tested and improved. This can help to increase customer confidence in your product and boost retention rates.</p>



<h2>How Does Automated Testing Change the Role of Quality Assurance?</h2>



<p>Automated testing is a way to evaluate the quality of software. The basic idea is that you write automated tests, or scripts, to check for unexpected behaviors or errors in the code.</p>



<p>Automated testers can run these scripts automatically, which saves time and effort for both developers and QA staff. When you have automated testing in place, you can focus on other tasks, like exploring new features or fixing bugs, without worrying about whether your application is running correctly.</p>



<p>There are two types of automated testing: static and dynamic. Static testing checks for basic issues like syntax errors, security holes, and database integrity. Dynamic testing checks for unexpected behaviors such as out-of-order execution, race conditions, and timeout issues.</p>



<p>QA teams use automated testing to maintain high standards of quality throughout the development process. They can catch issues early on in the development cycle and communicate findings effectively with developers and stakeholders.</p>



<p>By reducing bugs and improving overall quality, automated testing can help organizations achieve their goals more quickly and cost-effectively.</p>



<p>A Quality Assurance Engineers&#8217; role changes when embracing test automation testing. Their role will now be to enable the entire team to contribute tests to the automation pipeline. Test cases should be developed and run as part of the normal delivery process.</p>



<p>By making this transition, Quality Assurance Engineers can now focus on higher value work like covering edge cases, improving testing tools and methodology, and leveling up team members&#8217; skills in testing.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Test Automation Stages</h2>



<p>Test Automation includes several fundamental automation techniques that should be followed for quality testing. Testing automation systems are presented in stages atop test pyramids based on their hierarchy.</p>



<h3>Integration testing</h3>



<p>Integration tests measure whether logical integration is effective across all systems and can be achieved without unavoidable errors in integration. Incorporated testing is designed to test compliance with systems to determine how different modules interact.</p>



<h3>Unit testing</h3>



<p>Unit Testing means isolating your Application into unit testing and then checking its behavior independently of external parties or database configuration. Unit tests are often conducted throughout the build period and are considered the primary test phase.</p>



<h3>End-to-end testing</h3>



<p>Test frameworks for the testing of applications simulate user requirements to ensure they meet the needs of users at all levels. The final purpose is to ensure the application can be validated and checked by all the users.</p>



<h3>Exploratory testing</h3>



<p>Exploration testing can be regarded as a more advanced software testing strategy that involves learning, checking, and reviewing functional and visual components for users.</p>



<h3>Environmental Testing</h3>



<p>Building tests to validate the consistency that your software will be running in after deployment.</p>



<h2>Conclusion</h2>



<p>As you can see, automated testing is a cornerstone to DevOps. Most focus is generally put on running automated testing against software being developed. There are a lot of advantages to developing automated testing which also looks at environmental conditions as well. Accelerate your business by introducing automated testing tools today!</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>How to Modify VMWare ESXi Guest Files with Ansible</title>
		<link>https://www.valewood.org/ansible-modify-vmware-esxi-guest-file/</link>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Fri, 28 Oct 2022 01:25:15 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[Ansible]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[howto]]></category>
		<category><![CDATA[tools]]></category>
		<guid isPermaLink="false">/?p=1232</guid>

					<description><![CDATA[This post will help anyone who is attempting to use ansible to modify files on VMs running on ESXI via automation when Practicing DevOps. This method assumes that you have cloned out a machine, but do not yet have network&#8230;]]></description>
										<content:encoded><![CDATA[
<p>This post will help anyone who is attempting to use <a href="https://www.ansible.com/" data-internallinksmanager029f6b8e52c="7" title="Ansible">ansible</a> to modify files on VMs running on ESXI via automation when <a href="https://www.valewood.org/practicing-devops/">Practicing DevOps</a>.  This method assumes that you have cloned out a machine, but do not yet have network access to that machine meaning you would need to utilize native ESXi methods to get communication setup.  </p>



<p>I use methods like this in my home lab to help stay current with new trends in <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="How To Leverage the DevOps Methodology for Success!​" target="_blank" rel="noopener">DevOps</a> Not everyone is going to be fortunate enough to have cloud playgrounds to test out new things, and home labs are a great way to make a one-time investment in your future.</p>



<p>The code for the project can be found <a href="https://github.com/gwagner/ansible-examples/tree/main/modify-vmware-esxi-guest-file" target="_blank" data-type="URL" data-id="https://github.com/gwagner/ansible-examples/tree/main/modify-vmware-esxi-guest-file" rel="noreferrer noopener">here</a>!</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Prerequisites</h2>



<p>This article is going to assume that you already have VMWare running in a home lab somewhere. This also assumes that you have some familiarity with VMware and networking.</p>



<p>This post will also assume that you have already installed a baseline OS running open-vm-tools. <a href="https://www.packer.io/" data-internallinksmanager029f6b8e52c="17" title="Packer" target="_blank" rel="noopener">Packer</a><a href="https://www.packer.io/" target="_blank" rel="noreferrer noopener"></a> is a good tool to use to automate your baseline operating system installation to create a reusable disk image.</p>



<p>You may also want to read <a href="https://www.valewood.org/ansible-create-vmware-esxi-vm/" data-type="post" data-id="1213">this post</a> to get a good feeling about how to automate cloning images when vSphere or Center are not available solutions.</p>



<h2>The Playbook</h2>



<p>Below is the full code to copy SSH keys to a newly cloned machine, and set an IP address with a NetworkManager restart.</p>



<p>The general idea is to run <code>ansible-playbook modify-vmware-esxi-guest-file.yaml -i inventory.yaml</code> from your command line.  The playbook will then connect to ESXi and create a .ssh folder on your fresh machine.  It will then copy your local <code>/home/user/.ssh/id_rsa.pub</code> file to the remote machine.  Finally, it will run <code>/bin/nmcli </code>commands to get a static IP address set on the VM.</p>



<p>A majority of this playbook is also setup with <code>delegate_to: localhost</code>. This means that the computer running the ansible script will also execute anything with the defined <code><code>delegate_to</code>: localhost</code>. Since the remote machine from inventory exists but is not yet able to be connected to <code><code>delegate_to</code>: localhost</code> is necessary of you would immediately receive an ansible connection error.</p>



<pre class="wp-block-code yaml"><code>---
- name: Modify VMWare ESXi VM File
  hosts: all
  gather_facts: false
  tasks:
    - include_vars: config.yaml
      delegate_to: localhost

    - include_vars: creds.yaml # Remember, this should be in a vault
      delegate_to: localhost   # These creds are for example use only

    - name: Create .ssh folder
      community.vmware.vmware_guest_file_operation:
        validate_certs: false
        hostname: "{{ vmware_host }}"
        username: "{{ vmware_user }}"
        password: "{{ vmware_password }}"
        datacenter: ha-datacenter
        vm_id: "{{ vmware.name }}"
        vm_username: "{{ centos_template_user }}"
        vm_password: "{{ centos_template_password }}"
        directory:
          path: "/home/user/.ssh/"
          operation: create
          recurse: no
      delegate_to: localhost

    - name: Copy RSA to VM
      community.vmware.vmware_guest_file_operation:
        validate_certs: false
        hostname: "{{ vmware_host }}"
        username: "{{ vmware_user }}"
        password: "{{ vmware_password }}"
        datacenter: ha-datacenter
        vm_id: "{{ vmware.name }}"
        vm_username: "{{ centos_template_user }}"
        vm_password: "{{ centos_template_password }}"
        copy:
          src: "/home/user/.ssh/id_rsa.pub"
          dest: "/home/user/.ssh/authorized_keys"
          overwrite: yes
      delegate_to: localhost

    - name: Run command inside a virtual machine
      community.vmware.vmware_vm_shell:
        hostname: "{{ vmware_host }}"
        username: "{{ vmware_user }}"
        password: "{{ vmware_password }}"
        datacenter: ha-datacenter
        vm_id: "{{ vmware.name }}"
        vm_username: "{{ centos_template_user }}"
        vm_password: "{{ centos_template_password }}"
        vm_shell: "{{ item.shell }}"
        vm_shell_args: "{{ item.args }}"
      loop:
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.ignore-auto-dns yes" }
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.address \"{{ vmware.ip_address }}/24\"" }
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.gateway \"{{ vmware.gateway_address }}\"" }
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.dns \"{{ vmware.dns_address }}\"" }
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.method manual" }
        - { shell: "/bin/systemctl", args: "NetworkManager restart" }
      delegate_to: localhost

</code></pre>



<h2>Task By Task Breakdown</h2>



<p>To not rehash details I have gone through in other articles, you can find a breakdown of the inventory, credentials, and config in <a href="https://www.valewood.org/ansible-create-vmware-esxi-vm/#penci-A-Task-By-Task-Breakdown" data-type="URL" data-id="/ansible-create-vmware-esxi-vm/#penci-A-Task-By-Task-Breakdown">this post.</a></p>



<p>The first step of this playbook is to create a users .ssh folder so an authorized_keys file can be created.  The playbook makes an assumption that your user is named&#8230; user, but that could be modified and turned into a configuration parameter pretty quickly.  I will break down each of the config parameters below:</p>



<ul><li>validate_certs is set to false because most of us are not going to be using trusted 3rd party certs in our VMware environment. If you are doing this in a professional environment, ensure you have valid certs installed and leave validate_certs set to the default of true.</li><li>validate_certs should also be set to false if you are connecting to your VMWare server via IP address since your cert will not match an IP address.</li><li>vmware_user and vmware_password should be set to a user that has SSH access to your VMWare server. I would not recommend that you do this in any sort of production environment, but it is perfectly fine for a home lab.</li><li>datacenter is set to ha-datacenter. This is the default name of a “datacenter” in ESXi. There is no reason to change this.</li><li>vm_id is either the exact case-sensitive name of the virtual machine being configured.  If you created your machine using ansible, then make sure you map the name you gave it here via variables.</li><li>vm_username and vm_password is in reference to the user you setup when creating your template or disk image.  ESXi needs this to effectively run an interactive login to the server to perform your commands.</li><li>directory is signifying that our action is going to be taken on a directory.  In the next task you will see that we use the copy key instead of directory but we are utilizing the exact same module.</li><li>directory.path is the path on the ESXi guests that you want to take action on.</li><li>directory.operation denotes what we want to have happen.  In this case, we are going to create a directory.</li><li>directory.recurse tells ansible if it should send a command that recursively creates directories.  If your default user is not named user, you would end up with a /home/user/.ssh directory that will be fairly useless.</li></ul>



<pre class="wp-block-code yaml"><code>    - name: Create .ssh folder
      community.vmware.vmware_guest_file_operation:
        validate_certs: false
        hostname: "{{ vmware_host }}"
        username: "{{ vmware_user }}"
        password: "{{ vmware_password }}"
        datacenter: ha-datacenter
        vm_id: "{{ vmware.name }}"
        vm_username: "{{ centos_template_user }}"
        vm_password: "{{ centos_template_password }}"
        directory:
          path: "/home/user/.ssh/"
          operation: create
          recurse: no
      delegate_to: localhost</code></pre>



<p>This next task does a copy of a file from the machine you executed the ansible playbook from onto the ESXi guest that we are configuring.  In the interest of brevity, I am not going to rehash the duplicate keys from above.  Here are the specific keys of interest in this task:</p>



<ul><li>copy denotes that we want to copy a file.  The file needs to exist on your source system and will be copied to the ESXi guest.</li><li>copy.src is the path to the source file.  As you can see, we are targeting the public key here.</li><li>copy.dest is the full path to the destination.   As you can see we are targeting an authorized_keys file as the destination.  This could be dangerous if that file already exists as it will be overwritten.</li><li>copy.overwrite ensures that we will clobber whatever exists on the destination system with the file from our source system.</li></ul>



<pre class="wp-block-code yaml"><code>    - name: Copy RSA to VM
      community.vmware.vmware_guest_file_operation:
        validate_certs: false
        hostname: "{{ vmware_host }}"
        username: "{{ vmware_user }}"
        password: "{{ vmware_password }}"
        datacenter: ha-datacenter
        vm_id: "{{ vmware.name }}"
        vm_username: "{{ centos_template_user }}"
        vm_password: "{{ centos_template_password }}"
        copy:
          src: "/home/user/.ssh/id_rsa.pub"
          dest: "/home/user/.ssh/authorized_keys"
          overwrite: yes
      delegate_to: localhost</code></pre>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<p>This last task is composed a bit differently.  Effectively it is being used to run a series of nmcli commands along with a single systemctl command to set a static IP address for this machine.  I have this task composed this way to clean up ansible code.  This could be written as six fully independent tasks in ansible, but remember to stay DRY and don&#8217;t repeat yourself.  Here is a breakdown of the specific keys of interest:</p>



<ul><li>vm_shell represents the exact path to the command that is going to be run on the ESXi guest.  Do not include command arguments in this field, the documentation specifically states that it wants a full path to an executable.</li><li>vm_shell_args represents the arguments to the vm_shell command.  </li><li>loop controls how the task will loop through the data defined underneath.  I have the keys setup as dictionary objects so that we get both shell executables and arguments from the loop.</li></ul>



<pre class="wp-block-code"><code>    - name: Run command inside a virtual machine
      community.vmware.vmware_vm_shell:
        hostname: "{{ vmware_host }}"
        username: "{{ vmware_user }}"
        password: "{{ vmware_password }}"
        datacenter: ha-datacenter
        vm_id: "{{ vmware.name }}"
        vm_username: "{{ centos_template_user }}"
        vm_password: "{{ centos_template_password }}"
        vm_shell: "{{ item.shell }}"
        vm_shell_args: "{{ item.args }}"
      loop:
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.ignore-auto-dns yes" }
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.address \"{{ vmware.ip_address }}/24\"" }
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.gateway \"{{ vmware.gateway_address }}\"" }
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.dns \"{{ vmware.dns_address }}\"" }
        - { shell: "/bin/nmcli", args: "connection modify ens192 IPv4.method manual" }
        - { shell: "/bin/systemctl", args: "NetworkManager restart" }
      delegate_to: localhost</code></pre>



<h2>Conclusion</h2>



<p>As you can see, with a fairly concise set of steps, you can level up your DevOps automation game by rapidly configuring virtual machines in your home lab.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Do DevOps Engineers Write a lot of Scripting Code?</title>
		<link>https://www.valewood.org/devops-scripting/</link>
		
		<dc:creator><![CDATA[Greer Shepherd]]></dc:creator>
		<pubDate>Tue, 18 Oct 2022 21:45:38 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[coding]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[software]]></category>
		<category><![CDATA[tools]]></category>
		<guid isPermaLink="false">/?p=1180</guid>

					<description><![CDATA[Whether it’s Python, JavaScript, or other programming languages, Developers spend a lot of time writing code. More traditional infrastructure engineers are going to spend their time in a user interface configuring their systems and services to work for their organizations.&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Whether it’s Python, JavaScript, or other programming languages, Developers spend a lot of time writing code. More traditional infrastructure engineers are going to spend their time in a user interface configuring their systems and services to work for their organizations. Operations teams are going to be picking up what was developed for them by other groups and determine the right ways to run it efficiently.</p>



<p><strong><a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="How To Leverage the DevOps Methodology for Success!​" target="_blank" rel="noopener">DevOps</a> engineers are going to be performing configuration management efforts, software development, operations activities, and quality assurance activities. Each of these can be automated by writing code with scripting languages. This means that DevOps engineers write code!</strong></p>



<p>Let&#8217;s explore what this means to a DevOps engineer who may not be comfortable with code since they are coming from a practice that generally performs their activities inside of a user interface.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Why Scripting Code is Important</h2>



<p>Automation is important. It’s a key part of the DevOps process, which aims to reduce the time it takes to perform manual processes. Automation also increases the reliability and stability of those processes.</p>



<p>While a lot of people talk about it, they rarely talk about why. If you don’t have a good reason, there’s a good chance that you won’t see the benefits of automation in your organization. That’s why it helps to understand why you are automating in the first place.</p>



<p>DevOps organizations have a lot of tools and technologies that need to integrate together. DevOps engineers will spend almost every day automating these integrations utilizing a variety of scripting languages or DevOps tools.</p>



<p>When you spend your days configuring everything from <a href="https://aws.amazon.com/" data-internallinksmanager029f6b8e52c="14" title="AWS" rel="nofollow noopener" target="_blank">AWS</a> keys to the location of a database; it’s easy to understand why organizations want to reduce the amount of time spent doing it manually.</p>



<h2>DevOps and Scripts</h2>



<p>Those who work across multiple different technologies to build applications and services spend a ton of time configuring environments, virtual machines, and cloud providers.</p>



<p>That means developers have to learn how to use every single one of those tools. At first, this might feel like a chore; after all, no one wants to learn how to use Inversion of Control (IoC) or batch files to get something from AWS into their local computer or network.</p>



<p>When you look at it from the perspective of someone who spends most of his or her day typing in code and reading other people’s scripts—the process can seem more like an abomination than anything else.</p>



<p>A majority of engineers are writing scripts to make their jobs more efficient. Scripts are the shortcut version of automation. They’re designed to help engineers reduce the amount of time they spend doing system administration, delivering software to servers, monitoring systems, performing configuration management, managing cloud vendors, and many other activities.</p>



<p>I have always advocated if you perform an activity against a user interface that has an API then you should take the time to implement that activity in code via your scripting language of choice.</p>



<p>By scripting your changes out, you both get an opportunity to codify a change, but you have an opportunity to introduce that code into version control. This will help shift the responsibility of that code from a single person to an entire team.</p>



<p>Additionally, scripting gives you the opportunity to add comments to your code. Software developers utilizing high-level programming languages will add comments in their code so that the next person that picks up their work understands the intentions of their work. Changes through scripting should be treated the same way. When someone spends time writing scripts, those should be added to the collective code base and their peers should be able to understand the code and consume their work.</p>



<p>Contributing to the code base also allows that code to be integrated into CI/CD systems for future automated actions.</p>



<h2>Which DevOps Engineers Should be Working With Scripts?</h2>



<p>The first step in automating any process is figuring out who should do the automation. That can be tricky. It’s easy to think that the developers who spend most of their day writing code should be the ones to automate their work.</p>



<p>After all, they have all of the technical knowledge. But, depending on the organization, that might not be the best idea. In organizations using DevOps practices, developers aren’t soley responsible for creating new end-to-end application solutions.</p>



<p>Instead, everyone on the team is responsible for creating an entire infrastructure along with the entire DevOps lifecycle.</p>



<p>DevOps engineers are responsible for automating the deployment and operations process of software applications. They are responsible for automating everything from creating configuration files to configuring software environments.</p>



<p>Many DevOps engineers work with scripts. There are many reasons why this is the case. One reason is that scripts allow DevOps engineers to automate tasks that are repeatable across multiple environments and application iterations.</p>



<p>If an automated task must be performed multiple times during the development process, it makes sense to create a script that can be used in each environment. Another reason is that scripts help reduce errors by providing clear instructions on how to perform the task.</p>



<p>DevOps engineers should be knowledgeable about scripting languages, such as Bash, Python, Ruby, and Javascript. They should also be familiar with automation tools like <a href="https://www.docker.com/" data-internallinksmanager029f6b8e52c="16" title="Docker" rel="nofollow noopener" target="_blank">Docker</a> and <a href="https://www.ansible.com/" data-internallinksmanager029f6b8e52c="7" title="Ansible">Ansible</a>.</p>



<p>They should be able to identify areas where automation can improve their workflow and determine what types of changes are needed to make automation possible in their organization.</p>



<h2>Why is it So Hard to Transition from Scripting to Automation?</h2>



<p>It might seem like your engineers would love to transition from scripting to automation. After all, they are spending their day writing code.</p>



<p>Sometimes a jump from scripting to automation can be difficult. If scripts are not written in a way that they can be parameterized, those scripts will not fit into an overall automation structure natively. Additionally, when you’re used to customizing everything from your local machine to your cloud providers, the thought of learning a new configuration tool can seem like a nightmare.</p>



<p>All of this confusion can lead engineers to either choose not to automate at all or make bad choices about how to automate. The software development industry has an answer for this.</p>



<p>Most engineers will take a little bit of time to work through the transition from their previous role into one that is inclusive of DevOps. This is why it is so critical to work with the team on learning DevOps and embracing a full DevOps transition.</p>



<p>Most software development starts as writing scripts, shell scripting, or learning bash. From there, it will expand into utilizing different popular programming languages. If your background is in Office365 administration, you will not go through this general progression.</p>



<p>Developers should take new DevOps engineers under their wing and help them utilize tools that may not be ultimately familiar with. DevOps engineering is the combination of many different skill sets breaking down traditional barriers. Helping DevOps engineers write scripts that are able to be integrated into a larger set of automation will be a huge step forward for anyone feeling lost in this adoption.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>How to Get Started With Automation in a DevOps Organization</h2>



<p>DevOps engineers constantly improve their automation, but there’s a lot to learn. That’s why it’s important to bring on someone to help with the transition to automation.</p>



<p>There are a few things you can do to get started. First, look at your existing scripts and see if you have any that could be automated. Are there any tasks that are taking more time than they should? If so, you might want to take a closer look at them. Next, look at your existing infrastructure. Do you have a known, consistent state? If so, you might want to take a closer look at your scripts.</p>



<h2>Conclusion</h2>



<p>If you’re a DevOps engineer who is coming from a user interface, the idea of writing code that can automate different tasks may seem scary. You may feel overwhelmed by the scope of this responsibility and wonder whether you can actually do it.</p>



<p>To start, you can check out some resources that are available on <a href="https://www.github.com/" data-internallinksmanager029f6b8e52c="6" title="Github" rel="nofollow noopener" target="_blank">GitHub</a>. One of the best ways to get started is to dive right into the world of scripting. The Python programming language is great for beginner developers because it’s very easy to pick up and performs well under the hood. Python has a free online course available that teaches you the basics with a few projects you can complete.</p>



<p>Once you know your way around Python, you can move on to the next step. As you progress, you can check out some of the other scripting languages in use. There are many options out there, and most of them are open-source and available for use. Your best bet is to choose one that you feel comfortable with, and then get familiar with the basics. You can find plenty of tutorials and documentation on how to get started with any of them.</p>



<p>When you feel ready, you can start experimenting with the different ways to configure your systems.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Which Programming Language Should I Learn as a DevOps Engineer?</title>
		<link>https://www.valewood.org/devops-languages/</link>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Wed, 21 Sep 2022 22:11:50 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[software]]></category>
		<category><![CDATA[tools]]></category>
		<guid isPermaLink="false">/?p=344</guid>

					<description><![CDATA[DevOps&#160;is all about bringing software development and operations together under a single functional team to increase quality, communication, collaboration, and efficiency.&#160; Developers already have a background in development (duh), but a question I get asked frequently by operations engineers is&#8230;]]></description>
										<content:encoded><![CDATA[
<p><strong><a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="How To Leverage the DevOps Methodology for Success!​" target="_blank" rel="noopener">DevOps</a></strong>&nbsp;is all about bringing software development and operations together under a single functional team to increase quality, communication, collaboration, and efficiency.&nbsp; Developers already have a background in development (duh), but a question I get asked frequently by operations engineers is “Are there 4 top programming languages to learn for DevOps?”</p>



<p>Everyone could use a little bit of development in their life.&nbsp; It could be something as simple as a bash script to take care of a simple task, all the way up to running a blog like this one.&nbsp; Learning about the logical flow that a computer takes to compute everything is an empowering door to open when growing as a technology specialist in whatever field you specialize in.</p>



<p>There are numerous programming languages to choose from so it can be a bit daunting to narrow it down when doing research. Luckily, I have done some narrowing down for you!&nbsp; Below are a few of my favorite DevOps languages but this is by no means a definitive list.&nbsp; These are languages that I have used in my workflows and found some great success.</p>



<p>Let&#8217;s discuss some of the best programming languages for DevOps that can learn as someone with little to no experience so you can level up your DevOps game!</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>What is the difference between Interpreted vs Compiled Languages?</h2>



<p>The first concept that we should tackle is the difference between an interpreted language vs a compiled language.&nbsp; There are some specific semantics to get under your belt as part of your language selection process.&nbsp; In the world of DevOps, I would say that there really is not an incorrect choice here, but; DevOps is all about flow and your choices here can have an impact on your desired technology flow.</p>



<h3>Interpreted Langauge</h3>



<p>An interpreted language requires that a separate runtime be installed on your system which will generally perform a JIT runtime on the code you have written.&nbsp;&nbsp;</p>



<p>If I am writing code in Python, and I want that python to run on a remote Linux system, I need to have both the Python runtime installed on the remote system along with ensuring my code also exists on that system.</p>



<p>There is some practical utility to this.  Your systems require a dependency like Python, PHP, Ruby, Bash, etc. to be installed on the remote system, but you get a pretty good guarantee that you can write code once and use it in many places across many architectures.  The architecture (x86, ARM, SPARC, etc) has the runtime binaries installed (Python) and Just In Time “compile” (interprets) your code to be run on that architecture.  Pretty neat right?</p>



<p>In my opinion, interpreted languages are going to be some of the best programming languages for DevOps.  As long as the server or host you are going to run your code on has the interpreter installed, the process is as simple as copy > paste > run!</p>



<h3>Compiled Languages</h3>



<p>A compiled language requires that a full compilation happens prior to the code being runnable.&nbsp; In Windows land, think about this like a .exe file, or on Linux, this would be a binary.&nbsp;&nbsp;</p>



<p>If I am writing code in C++, and I want to run by C++ on a remote Linux system, I have 2 options.&nbsp; I can install C++ on the remote system, add my code to that system, run a compile step, and finally run my binary.&nbsp; Alternatively, I could compile my binary locally (ensuring I match the OS and CPU architecture as part of the compile step) and then distribute that binary to the remote system for execution.</p>



<p>Generally, a compiled language will be statically linked which means that there are zero additional dependencies that need to live on a remote system, unlike an interpreted language.  You do need to have a more detailed understanding of the remote system you will be deploying to so that your pre-compiled binary has a much better shot of being able to run on the destination.</p>



<p>Compiled languages are generally not the best languages for DevOps, at least not for beginners.  When starting out, you are going to go through a lot of trial and error.  This means a lot of wasted time also fighting compilers.  I would recommend waiting on compiled languages until you have a bit of experience under your belt.</p>



<h3>Need for Speed?</h3>



<p>Compiled languages are generally going to be faster than interpreted languages.&nbsp; A compiled application or script does not need to get converted from human-readable text into a binary that the CPU will understand.&nbsp; That compilation was done when the application was built.&nbsp; An interpreted language is going to need some kind of JIT compilation in order to be executed through the language&#8217;s runtime.&nbsp; In the PHP world, this JIT compilation is transforming human-readable text into OpCode.&nbsp; Once that OpCode is created then the PHP runtime can just execute what the OpCode tells it to execute.</p>



<p>When trying to do tool selection, there is generally an argument about the speed an application runs and whether the right tool is the fastest tool.&nbsp; When doing DevOps where you are generally trying to get a machine or environment into a specific state, the speed of the language itself is generally not your biggest impediment.&nbsp; Your biggest bottleneck will be remote resources like packages, downloads, etc.&nbsp; I would rather choose the right tool for the job inside of the ecosystem that I work in instead of trying to make my tool selection for DevOps based solely on performance.</p>



<h2>DevOps with Python</h2>



<p>Python is an interpreted language and was created in the 1980s by Guido van Rossum in the Netherlands.  It is widely adopted and widely used across the industry.  You can find Python pre-installed on most modern Linux distributions today, though there is still a bit of fracturing between Python 2.x and 3.x communities. Aside from Javascript, you will find that Python is easily one of the most popular programming languages out there today.</p>



<h3>How Big is the Python Community?</h3>



<p>Python has a strong community backing it.&nbsp; At the time of writing this, PyPI has ~391,000 packages with nearly 660,000,000 package downloads per day.&nbsp; PyPI is a package repository for Python where you can download community or vendor-developed code and add it directly to your project.&nbsp; There are a lot of pre-solved problems out there like connecting to a database.&nbsp; PyPI enables users to download packages like those database connectors automatically.</p>



<h3>What is the Utility of Python?</h3>



<p>Python has a lot of utility in the DevOps space.&nbsp; Since it is born out of the Linux and Unix ecosystem, it has some very strong ties to the Linux operating system for performing common tasks.&nbsp; It is so well suited for this task that <a href="https://www.ansible.com/" data-internallinksmanager029f6b8e52c="7" title="Ansible">Ansible</a>-Core is written in Python.&nbsp; Python is also runnable on Windows!</p>



<p>Python is clearly a good choice when it comes to writing automation code for DevOps, but it has a lot of other utilities as well.&nbsp; Much of the Big-Data space is using python for number crunching and machine learning specifically because the language lends itself well to that kind of computation.&nbsp; Being a dynamically typed language instead of a statically typed one, data transformations can be done quickly without a lot of overhead by the end user.</p>



<p>Being an interpreted language gives it a lot of power as well when it comes to distributing and running the code.&nbsp; Aside from activities like automated testing, packaging Python consists of compressing your directory structure, moving it to where you want, decompressing, and finally running the code.&nbsp; If there is a bug, you can also fix it in place, though I would recommend ensuring that you have centralized code repositories and follow a good process of version control and pushing new versions out.</p>



<h3>Python Learning Resources</h3>



<ul><li><a href="https://www.learnpython.org/" target="_blank" rel="noreferrer noopener">https://www.learnpython.org/</a></li><li><a href="https://www.codecademy.com/learn/learn-python" target="_blank" rel="noreferrer noopener">https://www.codecademy.com/learn/learn-python</a></li><li><a href="https://www.pythontutorial.net/python-basics/python-write-csv-file/" target="_blank" rel="noreferrer noopener">https://www.pythontutorial.net/python-basics/python-write-csv-file/</a></li></ul>



<h2>DevOps with JavaScript</h2>



<p>Nevertheless, Javascript may not have a lot of flexibility compared to Python but is still widely available to add value in DevOps. It can be incorporated as client code as well as server code. JavaScript is widely available on the web and has a huge footprint. If your work environments depend on Node.js, the ability to develop Javascript is an advantage. As with Python, JavaScript has an enormous user base. There are many Javascript projects that could benefit from this community.</p>



<p>Much like Python, is an interpreted language. Unlike Python, Javascript is easily multithreaded (async tasks on a single main thread) directly out of the box with no additional work required. Javascript creates immersive and interactive websites, can be used as a server-side scripting language, can be used for GUI development powering both mobile and desktop applications, and can be utilized to build fully functional server and client-side web-based applications. It really is the swiss army knife in this list of the best programming languages for DevOps.</p>



<p>If you start to work with Javascript, you will find that it is an extremely versatile language and it could be the right programming language for your specific cases. There is a reason why the community is as large as it is!</p>



<h3>How big is the Javascript Community?</h3>



<p>Javascript could probably be considered the most popular programming language at this point. I would not argue that by code volume, but I would argue that just about every single developer that has touched the internet has either developed, debugged, or been confused by Javascript. The community then got bigger with the advent of Node.JS. This moved code from the front end to the backend where it could easily be run on a server. At the time of writing, there are over 1.3 million NPM packages available for consumption.</p>



<h3>What is the Utility of Javascript?</h3>



<p>When it comes to DevOps engineers, Javascript is widely used across numerous cloud platforms as a configuration management tool, scripting language, or as traffic routing or traffic modification runtime. <a href="https://aws.amazon.com/" data-internallinksmanager029f6b8e52c="14" title="AWS" rel="nofollow noopener" target="_blank">AWS</a> Cloudfront uses Javascript as its primary configuration language in its event-driven Origin or Response systems. <a href="https://pages.cloudflare.com/" data-internallinksmanager029f6b8e52c="10" title="Cloudflare Pages" rel="nofollow noopener" target="_blank">Cloudflare pages</a> will utilize Javascript as its Functions framework for performing request modifications in line with internet requests.</p>



<p>DevOps engineers are going to need a pile of scripting languages at their disposal as we. If you are working in an environment that already has Node.JS included, then Javascript can be a really good language to use. This Blog uses Node.JS as its delivery pipeline through Cloudflare Pages to do some content manipulation between WordPress and publishing static pages.</p>



<h4>Additional Utility!</h4>



<p>Javascript can be utilized as an interactive command language directly from the browser through the Developer tools. An ICL lets you input code into a running environment to get information back. Through Developer Tools consoles, you are able to run code, print variable states, etc.</p>



<p>Popular tools like VSCode are also written in Javascript (TypeScript) using a tool called Electron. Electron is a cross-platform application framework for running Javascript, HTML, and CSS on desktop.</p>



<h3>Javascript Learning Resources</h3>



<ul><li><a target="_blank" rel="noreferrer noopener" href="https://www.codecademy.com/learn/introduction-to-javascript">https://www.codecademy.com/learn/introduction-to-javascript</a></li><li><a target="_blank" rel="noreferrer noopener" href="https://teamtreehouse.com/library/javascript-basics">https://teamtreehouse.com/library/javascript-basics</a></li><li><a target="_blank" rel="noreferrer noopener" href="https://www.learn-js.org/">https://www.learn-js.org/</a></li></ul>



<h2>DevOps with Golang</h2>



<p>Golang was originally designed at Google in 2007 as a replacement for C and C++.&nbsp; Go foregoes some of the more tedious facets of C and C++ like header files for type definitions.&nbsp; Go is also a compiled language instead of an interpreted language meaning that the result of something in Golang is going to be a binary.&nbsp; Golant has quickly grown in popularity and is the core language behind the very popular container orchestration framework <a href="https://kubernetes.io/" data-internallinksmanager029f6b8e52c="4" title="Kubernetes" rel="nofollow noopener" target="_blank">Kubernetes</a>.</p>



<h3>Community</h3>



<p>The size of the Golang community is tough to nail down because of the way that Go mod works.&nbsp; Go mod can be any git URL that has a go.mod and go.sum file in its repository.&nbsp; From there, go mod will check out the code, and check out the code&#8217;s dependencies all while doing dependency resolution in the background.&nbsp; Since git can be hosted anywhere, nailing down how many downloads a day without some kind of body providing central registration of packages like PyPI does, the best we can do is look at something like google trends for a baseline of activity.</p>



<script type="text/javascript" src="https://ssl.gstatic.com/trends_nrtr/3045_RC01/embed_loader.js"></script>
  <script type="text/javascript">
    trends.embed.renderExploreWidget("TIMESERIES", {"comparisonItem":[{"keyword":"/m/09gbxjr","geo":"US","time":"today 12-m"},{"keyword":"/m/06ff5","geo":"US","time":"today 12-m"},{"keyword":"/m/05z1_","geo":"US","time":"today 12-m"}],"category":0,"property":""}, {"exploreQuery":"geo=US&q=%2Fm%2F09gbxjr,%2Fm%2F06ff5,%2Fm%2F05z1_&date=today 12-m,today 12-m,today 12-m","guestPath":"https://trends.google.com:443/trends/embed/"});
  </script>



<p>As you can see by the graphic above, at the time of writing, Python is the dominant search in Google Trends compared to something like Golang.&nbsp; I would consider Golang a strong and growing community with projects like Kubernetes and CockroachDB along with large technology groups moving into using the stack like <a href="https://www.github.com/" data-internallinksmanager029f6b8e52c="6" title="Github" rel="nofollow noopener" target="_blank">GitHub</a> and Uber.</p>



<h3>Utility</h3>



<p>In my workflow, I am generally using Golang for 2 things; microservice apps and API middleware.</p>



<p>When I say microservice apps, I am generally not talking about something which is composed of a larger ecosystem.&nbsp; My microservice-type apps are usually tied into a Kubernetes stack.&nbsp; I had a particular challenge with <a href="https://linkerd.io/" data-internallinksmanager029f6b8e52c="3" title="Linkerd" rel="nofollow noopener" target="_blank">LinkerD</a> where I need to create a MutatingAdmissionWebhook to rewrite my HTTP(s) probes as in pod curl probes after setting my namespace to deny all.&nbsp; This was a good workaround to wrapping and rewriting many different helm charts to use curl probes instead of using standard HTTP(s) probes.</p>



<p>You can find that code <a href="https://github.com/gwagner/linkerd-convert-http-to-curl" target="_blank" rel="noopener">here</a>.&nbsp;&nbsp;</p>



<p>When doing API orchestration, I have written a few applications which will pull data from one API (or have data pushed via a webhook) into an application that may amend or transform the data before pushing it into another receiving API.&nbsp; This is particularly useful when trying to normalize data from system A to system B.&nbsp; This was particularly useful when moving from a Graphite-based metric TSDB system over to InfluxDB.&nbsp; We did not need to rewrite all of our metric collectors, we just needed to tap into the metric stream, do an on-the-fly conversion, and then output metrics to InfluxDB.</p>



<h3>Learning Resources</h3>



<ul><li><a href="https://www.udemy.com/course/go-building-devops-tools/" target="_blank" rel="noreferrer noopener">https://www.udemy.com/course/go-building-devops-tools/</a></li><li><a href="https://go.dev/learn/" target="_blank" rel="noreferrer noopener">https://go.dev/learn/</a></li><li><a href="https://www.codecademy.com/learn/learn-go" target="_blank" rel="noreferrer noopener">https://www.codecademy.com/learn/learn-go</a></li></ul>



<h2>DevOps with Ruby</h2>



<p>Because of its efficiency in DevOps, Ruby is a preferred scripting language for automating IT environments&#8217; repetitive tasks. In addition to web development, data science, and unit testing, this dynamic, interpreted programming language is used for DevOps. Ruby is also fairly simple to learn. As a result, the language has a fast-growing community of DevOps engineers. With no prior programming experience, beginners can get started with Ruby pretty quickly.&nbsp;</p>



<h3>Community</h3>



<p>Ruby is a difficult community to quantify fully simply because of how spread out it is.&nbsp; Ruby Gem can be a good baseline metric with roughly ~174,000 gems available from RubyGems.org and 111B+ (yeah, billion) downloads.&nbsp; If you look past ruby gems, the second most popular place that ruby is being utilized is with <a href="https://www.chef.io/" data-internallinksmanager029f6b8e52c="8" title="Chef">Chef</a>.&nbsp; The marketplace has roughly 4,000 cookbooks with roughly ~80,0000 maintainers</p>



<h3>Utility</h3>



<p>Ruby has some great utility when it comes to DevOps automation.&nbsp; When building out an early DevOps-focused monitoring stack, we chose Sensu Core due to its configuration-driven and scalable design.&nbsp; Most of the community-produced checks at that point were written in ruby which lent itself very well to building reusable consistent libraries that were well-tested.</p>



<p>Much like the Golang example above, I have also utilized ruby as an API middleware for doing data payload manipulations.&nbsp; Prior to <a href="https://www.docker.com/" data-internallinksmanager029f6b8e52c="16" title="Docker" rel="nofollow noopener" target="_blank">Docker</a> supporting <a href="https://docs.docker.com/config/containers/logging/json-file/" target="_blank" rel="noopener">JSON File Logging</a>, there were very long debates about what separation between log entries means between different programming languages.&nbsp; Ruby was used in an environment where I was working into tail log output from containers and based on its configuration, properly parse and package logs to be sent to centralized logging systems upstream with additional metadata.</p>



<h3>Learning Resources</h3>



<ul><li><a href="https://gorails.com/" target="_blank" rel="noreferrer noopener">https://gorails.com/</a></li><li><a href="https://www.chef.io/" target="_blank" rel="noreferrer noopener">https://www.chef.io/</a></li></ul>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Security Considerations</h2>



<p>When utilizing any code for any function whether it be DevOps or software development, you should always be concerned about security.&nbsp; Let’s say you have a 3-year-old server sitting around and its original automation code has not had any electricity run through it in the same time frame.&nbsp; That server&#8217;s automation code is probably outdated enough that there is at least some kind of CVE attached to it.&nbsp; This will be particularly easy to find if you are doing robust infrastructure scanning but will be much more obscure if you are running compiled binaries where the source code is not under some kind of routine scrutiny.&nbsp; Regardless of how you are building and running code, please make sure to clean up after yourself and avoid getting attacked by leaving a trail of outdated technology behind you.</p>



<h3>Supply Chain Attacks</h3>



<p>Supply chain attacks are all the rage these days.&nbsp; Consider the supply chain of your code dependency management system.&nbsp; Are you routinely scanning it for CVEs?&nbsp; Are you doing any kind of dynamic automated or manual testing of the code looking for vulnerabilities?&nbsp; Are you sure you can trust the source of your code dependencies?</p>



<p>DevOps code can be commonly overlooked in a supply chain attack scenario.&nbsp; Maybe you are writing a console tool to help make your life a little bit easier.&nbsp; You go ahead and pull in a few libraries from the internet to help aid in the creation of that tool like colored output.&nbsp; You also want to be really good and write automated tests as a best practice and you need help generating some data for those tests.&nbsp; Without a persistent review of code dependencies, the OSS developer/contributor of one of the dependencies that you are utilizing is tired of their <a href="https://www.bleepingcomputer.com/news/security/dev-corrupts-npm-libs-colors-and-faker-breaking-thousands-of-apps/" target="_blank" rel="noopener">work being used for free without any recognition or compensation</a> and deliberately destroys the project.&nbsp; There are also less directly malicious scenarios where the developer of a <a href="https://blog.sonatype.com/npm-project-used-by-millions-hijacked-in-supply-chain-attack" target="_blank" rel="noopener">popular package gets targeted and code is unknowingly slipped into their project</a>.</p>



<p>The lesson is this: assume that attack vectors are everywhere and ensure that you are scanning everything you can get your hands on for CVEs.&nbsp; The industry has a good focus on this now, and the question is not IF you will get compromised, but when.&nbsp; Keep yourself safe by being proactive.</p>



<h2>What Languages do I Use Most Often?</h2>



<p>When I am sitting down to take care of simple tasks or to write scripts for a problem I am trying to solve; I am most often looking at a language that can help me do data manipulation, develop operational automation, build infrastructure as code, or build a deployment pipeline for my projects.</p>



<h3>What do I use for Data Manipulation?</h3>



<p>For me, this is generally a quick and dirty task that I am not going to be releasing to production in any form. This website does a bunch of different data manipulation tasks under the covers as part of its pipeline. I will generally choose PHP (not on this list, but it is a majority of my pure software dev background) or Javascript.</p>



<p>Javascript is a fairly common language utilized in a multitude of DevOps environments that I would be able to quickly onboard someone with if needed. All of the tasks I am doing here are also fairly simple tasks in need of a simple language. I am not trying to do big data analytics, just mutate some links, move around some HTML, and soon do some automated testing.</p>



<h3>What do I use for Infrastructure Management (or Infrastructure as Code)?</h3>



<p>I have a Home Lab where the WYSIWG part of this website is hosted. I push all of my changes there as part of a continuous integration pipeline through Ansible. This means that I am living in the Python space.</p>



<p>It could be easy to argue that I am not really using Python here. I am for sure not a full-fledged Python programmer, but I have dug through a fair bit of the source code behind Kubespray to understand the real intentions of what it is trying to accomplish. This has also helped me utilize Ansible as a swiss army knife for any of my infrastructure management needs.</p>



<h3>What do I use for Deployment Pipelines?</h3>



<p>I currently utilize a mixture of Javascript and GitHub Actions and GitOps to build deployment pipelines. There are a variety of other languages I could be using, but these work well for me. As stated earlier, I will shift all of my data around with Javascript. From there, GitHub actions will run any builds that I need with any triggered deploys.</p>



<p>If the end result needs to go on the internet, I don&#8217;t really need to deal with a full-weight object-oriented programming language, Linux servers/Linux systems, relational databases, business intelligence, or anything like that. It makes more sense for GitOps-style triggers to be in place to automagically move my code from the repo to the internet without manual intervention.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>What is the Best General Purpose Programming Language?</h2>



<p>I think you need to first ask, what is most native to my environment. If Node.JS is not installed on every single one of your servers, but you want to write all your scripts in Javascript, that is going to be tough.</p>



<p>If you are looking for a one-size fits all answer, then you are not going to find one. I would keep your mind open, try out new things, and see what fits the situation you are in.</p>



<h2>What is the Best Language for DevOps?</h2>



<p>In my opinion, the best general-purpose programming language (and the best language for DevOps) is going to be Python.  While I am a fan of GoLang for numerous reasons, python has been battle-tested in this space since before DevOps was a coined methodology in the technology space.  Other languages absolutely have some specific utility in the space, but i would consider Python to easily be the reigning champion of the best language for DevOps.</p>



<h2>Conclusion</h2>



<p>As I stated at the beginning of this article, this is by no means a definitive list. I do not believe there is an answer to the question &#8220;Which Programming Language Should I Learn as a DevOps Engineer?&#8221;.  This is a list of some of the tools that I utilized to build effective DevOps workflows and to enable the flow of delivery.  I utilize these tools at my job along with utilizing these tools in my homelab.  I believe that everyone could use a little bit of software development in their life.  Python, Javascript, Golang, or Ruby are really great places to start with languages because of their utility, communities, and ties to DevOps and DevOps tooling.</p>



<p>There are absolutely other programming languages that are not on this list. If you feel like I have left anything out that is very relevant to DevOps technologies and system administration, or are just common languages that are being utilized frequently, don&#8217;t hesitate to contact me and I can update the list.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>What essential DevOps tools should you be using today?</title>
		<link>https://www.valewood.org/essential-devops-tools/</link>
					<comments>https://www.valewood.org/essential-devops-tools/#respond</comments>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Sun, 11 Sep 2022 17:03:41 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[sdlc]]></category>
		<category><![CDATA[tools]]></category>
		<guid isPermaLink="false">/?p=5</guid>

					<description><![CDATA[The goal of any DevOps tool should be to help your team communicate more effectively, automate manual tasks, and track the progress of your projects. With the right tools, you can significantly speed up your development process and produce better&#8230;]]></description>
										<content:encoded><![CDATA[
<p>The goal of any <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="How To Leverage the DevOps Methodology for Success!​" target="_blank" rel="noopener">DevOps</a> tool should be to help your team communicate more effectively, automate manual tasks, and track the progress of your projects. With the right tools, you can significantly speed up your development process and produce better results. In this post, you’ll find a list of the most essential DevOps tools and advice on how to choose the right ones for your team.</p>



<h2><strong>Build Tools</strong></h2>



<p>Build tools are an important cornerstone for any kind of DevOps workflow. Just choosing one without doing an evaluation can mean the difference between success and failure in a lot of circumstances. The build tooling must jive with the team and accomplish producing the CI/CD processes which the team expects in the way they expect them to be run. Think of them as task runners with a GUI, but each task runner has its own flare. Below is a list of tools that are widely used and could fit the bill for your next project.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h3>Jenkins</h3>



<p>If you have spent any time in the software space, or have done any googling around building software, Jenkins is sure to be the first thing that pops up. Jenkins is an open-source automation tool used for continuous integration and continuous delivery (CI/CD). Companies use it to automate the software development process, build and test their code, and deploy their applications. Jenkins is a highly configurable tool that allows you to choose from a large range of plugins. These plugins allow you to integrate Jenkins with other tools such as <a href="https://www.docker.com/" data-internallinksmanager029f6b8e52c="16" title="Docker" rel="nofollow noopener" target="_blank">Docker</a> Hub, <a href="https://www.atlassian.com/software/jira" data-internallinksmanager029f6b8e52c="21" title="Jira" rel="nofollow noopener" target="_blank">JIRA</a>, and others. Jenkins can be used for DevOps to automate the software delivery process, deploy apps, and manage infrastructure.</p>



<h3>Atlassian Bamboo</h3>



<p>Atlassian Bamboo is a platform for building and managing builds and deployments of software. It is generally utilized due to its tie-ins with other Atlassian products such as Jira and Confluence giving you an entire ecosystem out of the box. It is a great option if you are working in a team and want to set up a standardized process for building your code. Bamboo allows you to set up different stages of your workflow, each with its own set of tasks. This way, you can create a dev stage where your team has access to the latest version of the code and works directly from it, a test stage where your team can run tests on the latest version of the code and a production stage to deploy the code once it has been tested. As a rule of thumb, if you are working in a team that is already entrenched in the Atlassian ecosystem, go for Bamboo.</p>



<h3>Drone CI</h3>



<p>Drone bills itself as a &#8220;Self Service Continuous Integration System&#8221;, but I think you can really view any of the tools listed under build as exactly that. If you are looking for the more modern cool kid on the block, Drone CI is probably going to be a pretty good choice. Drone CI is natively built around Docker and the container ecosystem. This makes building modern applications more intuitive for individuals who are accustomed to the container ecosystem already. Drone CI also supports other types of containers, such as rkt. For developers who are not as familiar with Docker, Drone CI does have a user interface that allows you to manually configure a build environment. Drone also has a plug-in architecture, which means that you can also extend Drone’s capabilities with your own plug-ins, allowing you to configure a custom build environment as well.</p>



<h3>Travis CI</h3>



<p>Travis CI is a bit of a unique take amongst its competitors listed above. Travis CI is not a service you would normally go and locally install in your data center. Its origins are built under the idea that building environments should be ephemeral, cheap, easy, and defined via software. Their service allows you to create a new build environment by just pushing code to your <a href="https://www.github.com/" data-internallinksmanager029f6b8e52c="6" title="Github" rel="nofollow noopener" target="_blank">GitHub</a> repository. The great thing about this is that it allows you to create any type of environment you want. In the case of Travis CI, they allow you to build your environment in a way that is open source and completely controlled by you.</p>



<h3>GitHub Actions</h3>



<p>GitHub Actions is a new entrant to the build and deploy space, and frankly, the next logical step in GitHub&#8217;s journey of code hosting. GitHub has become the de-facto standard for hosting code, and Actions takes it a step further by allowing you to programmatically trigger a series of actions on your code, such as building, testing, publishing, and deploying it. Actions is a game changer as it allows anyone to create their own automated workflow without the need for any additional software. For example, let’s say you want to deploy your code to your staging environment every time you push a new commit to your master branch. You can now easily set up an action that listens for new commits on the master branch, checks out the code, kicks off a build process, and then deploys the code to your staging environment.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>In this space, I am a fan of the tool that gets the job done. I don&#8217;t have any particular allegiances because build tools are just dumb task runners. Maybe a UI speaks to you more, or a set of tools plugs into an ecosystem more seamlessly than another tool. Either way, do a bit of evaluation and make sure you are not painting yourself into a corner, and you will be just fine with any of these tools. Sign up for free trials, do a bit of exploring, and if you have questions, there is a vibrant community of people who are happy to help! Stay tuned to blog posts, newsletters and social media to stay up to date on new features and helpful tips and tricks!</p>



<h2><strong>Server Configuration Management</strong></h2>



<p>Below, <a href="https://puppet.com/" data-internallinksmanager029f6b8e52c="9" title="Puppet">Puppet</a> and <a href="https://www.chef.io/" data-internallinksmanager029f6b8e52c="8" title="Chef">Chef</a>, are the two 5000-pound gorillas in the room when it comes to configuration management DevOps tools. Other competitors exist in the space, but I would argue always live on the fringes and are not really taking any market share away from these two primary options any time soon. Some would argue that <a href="https://www.ansible.com/" data-internallinksmanager029f6b8e52c="7" title="Ansible">Ansible</a> should be in this category as well, but I would argue that Ansible is a task orchestrator and NOT a configuration management tool. Give Ansible tasks, it orchestrates tasks, and when it completes someone will need to write more code to determine if the task was executed correctly. In my eyes, DSCM-level validation of completion is a core feature that a configuration management system should have out of the box, otherwise, it is a task orchestrator masquerading around to be something like a configuration management DevOps tool. Don&#8217;t get me wrong, there is still a spot in my heart for Ansible, just not under configuration management.</p>



<h3>Puppet </h3>



<p>Puppet is an open-source tool for managing infrastructure as code (IaC). It’s often used for configuration management, service deployment, and continuous delivery. Puppet works by installing agents on different system types and installing the Puppet server on one or more machines. The Puppet server manages the agents to configure the systems based on user-defined policies. It can be used with DevOps to manage configuration policies, provision and configure infrastructure, and automate deployment. When using Puppet myself, I normally do not connect Puppet back to a Puppet master. I run puppet headless so that my idempotent builds can be deployed and triggered at will. This also helps avoid some of the licensing costs of Puppet. As of the writing of this post, their pricing is also hidden behind a contact wall. This generally means: &#8220;If you have to ask, you probably can&#8217;t afford it&#8221;.</p>



<h3>Chef</h3>



<p>Chef is an open-source tool for managing infrastructure as code (IaC). It’s often used for configuration management, service deployment, and continuous delivery. Chef works by installing agents on different system types and installing the Chef server on one or more machines. The Chef server manages the agents to configure the systems based on user-defined policies. It can be used with DevOps to manage configuration policies, provision and configure infrastructure, and automate deployment. When using Chef myself, I normally do not connect Chef back to a Chef master. I run puppet headless so that my idempotent builds can be deployed and triggered at will. This also helps avoid some of the licensing costs of Chef.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>As you can see, the descriptions of the tools are nearly identical. The primary difference between these two tools is going to be the community supporting package availability, price, and their specific DSL. Chef is primarily Ruby driven which gives you a TON of flexibility when you need it by diving into the Ruby space. This is an antipattern so use it sparingly, but it can be helpful in a pinch. I would also argue that the Chef community is currently much stronger than the Puppet community having many more packages developed and maintained by the community. In my career, I started with Puppet and converted to Chef simply for that fact.</p>



<h2><strong>Infrastucture Configuration Management</strong></h2>



<p>In this post, I am going to be focusing on <a href="https://aws.amazon.com/" data-internallinksmanager029f6b8e52c="14" title="AWS" rel="nofollow noopener" target="_blank">AWS</a> and <a href="https://azure.microsoft.com/en-us/get-started/azure-portal" data-internallinksmanager029f6b8e52c="20" title="Azure" rel="nofollow noopener" target="_blank">Azure</a> as the primary examples of IaC CM tools. I am explicitly ignoring GCP, <a href="https://www.digitalocean.com/" data-internallinksmanager029f6b8e52c="5" title="DigialOcean" rel="nofollow noopener" target="_blank">DigitalOcean</a>, etc. because every cloud vendor has its own APIs, its own tool sets, and its own concepts which are really all born from what AWS and Azure have already pioneered.  If you are interested in the most marketable DevOps tools focusing on infrastructure configuration management, then these are the tools I would focus on first.</p>



<h3>AWS CloudFormation</h3>



<p>AWS CloudFormation is a native toolset provided by AWS which is utilized to configure their cloud platform. It enables you to configure your cloud infrastructure and also create templates for future usage. These templates can be used to create infrastructure as code, which is a best practice in terms of cloud adoption. CloudFormation provides you with a lot of flexibility as compared to other tools, but it is not easy to start with.</p>



<h3>Azure ARM Templates</h3>



<p>Using an ARM template, you can declaratively create and deploy Azure infrastructure, including virtual machines, networks, storage systems, and any other resources you require. The template simply describes what you want to happen, and Azure takes care of the details. You can also use templates to generate code or scripts to create or customize resources. Versioning: You can keep track of changes to your templates by keeping them in source control, just like you would any other code. You can also use templates to generate reports, giving you an easy way to track changes to your infrastructure. Reusability: You can create a library of templates to use in different scenarios.</p>



<h3>Terraform</h3>



<p>Terraform is a cross-cloud IaC tool produced by HasiCorp. They take a unique view of IaC where components that span across multiple clouds should be abstracted out for future reuse. Terraform is also a unique tool in that its open source, but has a paid enterprise version with additional features. Terraform is a great fit for enterprise environments where you want to maintain strict version control of your cloud infrastructure, have strict regulatory requirements, or have a dedicated team managing the infrastructure where you want to streamline your process with a tool that can enforce policies across the organization.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I really don&#8217;t have a right or wrong answer for this space. I do believe that if you have a need to get into the deepest nooks and crannies of a cloud hosting vendor, using native tooling (CloudFormation and ARM Templates) will always beat what Terraform has to offer. If you are looking to be a bit more functional cross-cloud by providing an interface for your organization to consume, Terraform is probably a better option.</p>



<h2><strong>Monitoring and Observability</strong></h2>



<p>I believe that there is no right answer to monitoring and observability as long as the answer doesn&#8217;t work for the team that needs to receive the alerts. If you are using a 24&#215;7 on-call system like OpsGenie, and your technologists refuse to install the application on their devices to get notified, it is probably the wrong way to go about ensuring someone is alerted to issues. The tools listed below range from out-of-the-box to highly customizable tools. Each approach has its advantages and disadvantages. If you are going to go with highly customizable and integrate that directly into your pipelines, then the team must be on board with the idea of additional maintenance in code space rather than the GUI space, and vice-versa for the out-of-the-box tools. As long as you and your team agree on the strong fundamentals of &#8220;99.9% of the time, get an alert that something is wrong before someone else notices and reports it&#8221;, then you at least have a good foundation to start selecting monitoring from.</p>



<h3>LogicMonitor</h3>



<p>From physical hardware to software applications, to virtual hosts, to network devices, to cloud infrastructure — LogicMonitor monitors it all. LogicMonitor is able to monitor virtual environments with its application monitoring capabilities. It can also monitor physical environments with its physical monitoring capabilities. With LogicMonitor’s comprehensive monitoring capabilities, it’s no wonder that it’s the monitoring software of choice for thousands of organizations worldwide.</p>



<h3>Sensu </h3>



<p>It works with any monitoring tool, like Graphite, Collectd, Elastic, and more. It can also receive data from other loggers, like statsd, in real-time. Sensu Go can collect data from virtually any source, maintain it in a data store for analysis, and send it to any output, including email, mobile push notifications, or synchronous or asynchronous webhooks. It is open source, flexible, and extensible with a wide range of configuration options.</p>



<h3>Prometheus</h3>



<p><a href="https://prometheus.io/" data-internallinksmanager029f6b8e52c="2" title="Prometheus" rel="nofollow noopener" target="_blank">Prometheus</a> is a popular open-source monitoring system for metrics, logs, and events. It enables querying, graphing, and alerting on time-series data. It collects metrics from a variety of sources, including systems and applications, and stores the metrics data in a data store. The metrics data is then made available for analysis via a variety of tools. Prometheus has a flexible architecture and can be deployed on-prem or in the cloud. It is highly scalable and can support metrics from any type of application. It is widely used by enterprises to monitor their production systems.</p>



<h2><strong>Task Runners / Orchestration Tools</strong></h2>



<p>I am only putting one tool in this section because I believe that there is only one tool worth talking about. That DevOps tool is Ansible.  Ansible is like a swiss army knife of task orchestration and your ability to hop in and out of specific contexts is unparalleled.</p>



<h3>Ansible</h3>



<p>Ansible is a tool for automating tasks across multiple devices &#8211; from physical hosts to virtual machines and even cloud providers. It allows you to programmatically automate tasks and workflows, and it’s the most widely adopted open-source automation tool in the world. In fact, according to the 2017 State Of Configuration Management Survey, Ansible is the most widely used configuration management tool in enterprises. Unlike other tools, Ansible requires very little upfront investment — you can get started with a free download. Additionally, there are many ways to scale Ansible beyond a single node, including cloud services like AWS, Microsoft Azure, or Google Cloud Platform.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>If you are looking to orchestrate events across multiple machines, services, or clouds; I honestly do not know why you would choose anything else.  I have used ansible to manage 1000+ machines in a data center orchestrating events across servers, services, clouds, and physical equipment all while making the intentions of the orchestration very clear to future engineers.</p>



<h2><strong>Conclusion</strong></h2>



<p>DevOps is a set of practices that combines software development and operations to shorten the development life cycle and provide continuous delivery and faster time to market. It’s a culture shift that requires collaboration between Development and Operations teams. The tools used in DevOps can be customized to meet the unique needs of your organization. These tools can automate the software delivery process, provision and configure infrastructure, and deploy applications.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.valewood.org/essential-devops-tools/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
