<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	 xmlns:media="http://search.yahoo.com/mrss/" >

<channel>
	<title>devops &#8211; A DevOps Blog</title>
	<atom:link href="https://www.valewood.org/tag/devops/feed/" rel="self" type="application/rss+xml" />
	<link>https://www.valewood.org/</link>
	<description>Occasionally a developer makes an Ops!</description>
	<lastBuildDate>Sun, 25 Sep 2022 16:55:42 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.0.2</generator>

<image>
	<url>https://www.valewood.org/wp-content/uploads/2022/08/A-DevOoops-1-e1660773390219.png</url>
	<title>devops &#8211; A DevOps Blog</title>
	<link>https://www.valewood.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Which programming language should I learn as a DevOps engineer?</title>
		<link>https://www.valewood.org/devops-languages/</link>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Wed, 21 Sep 2022 22:11:50 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[software]]></category>
		<category><![CDATA[tools]]></category>
		<guid isPermaLink="false">/?p=344</guid>

					<description><![CDATA[DevOps is all about bringing software development and operations together under a single functional team to increase quality, communication, collaboration, and efficiency.&#160; Developers already have a background in development (duh), but a question I get asked frequently by operations engineers&#8230;]]></description>
										<content:encoded><![CDATA[
<p><a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a> is all about bringing software development and operations together under a single functional team to increase quality, communication, collaboration, and efficiency.&nbsp; Developers already have a background in development (duh), but a question I get asked frequently by operations engineers is “Are there languages to learn for DevOps?”</p>



<p>Everyone could use a little bit of development in their life.&nbsp; It could be something as simple as a bash script to take care of a simple task, all the way up to running a blog like this one.&nbsp; Learning about the logical flow that a computer takes to compute everything is an empowering door to open when growing as a technology specialist in whatever field you specialize in.&nbsp; Below are a few of my favorite DevOps languages but this is by no means a definitive list.&nbsp; These are languages that I have used in my workflows and found some great success.</p>



<p>Let’s discuss some of the languages you can learn as someone with little to no experience so you can level up your DevOps game!</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Interpreted vs Compiled Languages</h2>



<p>The first concept that we should tackle is the difference between an interpreted language vs a compiled language.&nbsp; There are some specific semantics to get under your belt as part of your language selection process.&nbsp; In the world of DevOps, I would say that there really is not an incorrect choice here, but; DevOps is all about flow and your choices here can have an impact on your desired technology flow.</p>



<h3>Interpreted Langauge</h3>



<p>An interpreted language requires that a separate runtime be installed on your system which will generally perform a JIT runtime on the code you have written.&nbsp;&nbsp;</p>



<p>If I am writing code in Python, and I want that python to run on a remote Linux system, I need to have both the Python runtime installed on the remote system along with ensuring my code also exists on that system.</p>



<p>There is some practical utility to this.&nbsp; Your systems require a dependency like Python, PHP, Ruby, Bash, etc. to be installed on the remote system, but you get a pretty good guarantee that you can write code once and use it in many places across many architectures.&nbsp; The architecture (x86, ARM, SPARC, etc) has the runtime binaries installed (Python) and Just In Time “compile” (interprets) your code to be run on that architecture.&nbsp; Pretty neat right?</p>



<h3>Compiled Languages</h3>



<p>A compiled language requires that a full compilation happens prior to the code being runnable.&nbsp; In Windows land, think about this like a .exe file, or on Linux, this would be a binary.&nbsp;&nbsp;</p>



<p>If I am writing code in C++, and I want to run by C++ on a remote Linux system, I have 2 options.&nbsp; I can install C++ on the remote system, add my code to that system, run a compile step, and finally run my binary.&nbsp; Alternatively, I could compile my binary locally (ensuring I match the OS and CPU architecture as part of the compile step) and then distribute that binary to the remote system for execution.</p>



<p>Generally, a compiled language will be statically linked which means that there are zero additional dependencies that need to live on a remote system, unlike an interpreted language.&nbsp; You do need to have a more detailed understanding of the remote system you will be deploying to so that your pre-compiled binary has a much better shot of being able to run on the destination.</p>



<h3>Need for Speed?</h3>



<p>Compiled languages are generally going to be faster than interpreted languages.&nbsp; A compiled application or script does not need to get converted from human-readable text into a binary that the CPU will understand.&nbsp; That compilation was done when the application was built.&nbsp; An interpreted language is going to need some kind of JIT compilation in order to be executed through the language&#8217;s runtime.&nbsp; In the PHP world, this JIT compilation is transforming human-readable text into OpCode.&nbsp; Once that OpCode is created then the PHP runtime can just execute what the OpCode tells it to execute.</p>



<p>When trying to do tool selection, there is generally an argument about the speed an application runs and whether the right tool is the fastest tool.&nbsp; When doing DevOps where you are generally trying to get a machine or environment into a specific state, the speed of the language itself is generally not your biggest impediment.&nbsp; Your biggest bottleneck will be remote resources like packages, downloads, etc.&nbsp; I would rather choose the right tool for the job inside of the ecosystem that I work in instead of trying to make my tool selection for DevOps based solely on performance.</p>



<h2>DevOps with Python</h2>



<p>Python is an interpreted language and was created in the 1980s by Guido van Rossum in the Netherlands.&nbsp; It is widely adopted and widely used across the industry.&nbsp; You can find Python pre-installed on most modern Linux distributions today, though there is still a bit of fracturing between Python 2.x and 3.x communities.</p>



<h3>Community</h3>



<p>Python has a strong community backing it.&nbsp; At the time of writing this, PyPI has ~391,000 packages with nearly 660,000,000 package downloads per day.&nbsp; PyPI is a package repository for Python where you can download community or vendor-developed code and add it directly to your project.&nbsp; There are a lot of pre-solved problems out there like connecting to a database.&nbsp; PyPI enables users to download packages like those database connectors automatically.</p>



<h3>Utility</h3>



<p>Python has a lot of utility in the DevOps space.&nbsp; Since it is born out of the Linux and Unix ecosystem, it has some very strong ties to the Linux operating system for performing common tasks.&nbsp; It is so well suited for this task that <a href="https://www.ansible.com/" data-internallinksmanager029f6b8e52c="7" title="Ansible">Ansible</a>-Core is written in Python.&nbsp; Python is also runnable on Windows!</p>



<p>Python is clearly a good choice when it comes to writing automation code for DevOps, but it has a lot of other utilities as well.&nbsp; Much of the Big-Data space is using python for number crunching and machine learning specifically because the language lends itself well to that kind of computation.&nbsp; Being a dynamically typed language instead of a statically typed one, data transformations can be done quickly without a lot of overhead by the end user.</p>



<p>Being an interpreted language gives it a lot of power as well when it comes to distributing and running the code.&nbsp; Aside from activities like automated testing, packaging Python consists of compressing your directory structure, moving it to where you want, decompressing, and finally running the code.&nbsp; If there is a bug, you can also fix it in place, though I would recommend ensuring that you have centralized code repositories and follow a good process of version control and pushing new versions out.</p>



<h3>Learning Resources</h3>



<ul><li><a href="https://www.learnpython.org/" target="_blank" rel="noreferrer noopener">https://www.learnpython.org/</a></li><li><a href="https://www.codecademy.com/learn/learn-python" target="_blank" rel="noreferrer noopener">https://www.codecademy.com/learn/learn-python</a></li><li><a href="https://www.pythontutorial.net/python-basics/python-write-csv-file/" target="_blank" rel="noreferrer noopener">https://www.pythontutorial.net/python-basics/python-write-csv-file/</a></li></ul>



<h2>DevOps with Golang</h2>



<p>Golang was originally designed at Google in 2007 as a replacement for C and C++.&nbsp; Go foregoes some of the more tedious facets of C and C++ like header files for type definitions.&nbsp; Go is also a compiled language instead of an interpreted language meaning that the result of something in Golang is going to be a binary.&nbsp; Golant has quickly grown in popularity and is the core language behind the very popular container orchestration framework <a href="https://kubernetes.io/" data-internallinksmanager029f6b8e52c="4" title="Kubernetes" rel="nofollow noopener" target="_blank">Kubernetes</a>.</p>



<h3>Community</h3>



<p>The size of the Golang community is tough to nail down because of the way that Go mod works.&nbsp; Go mod can be any git URL that has a go.mod and go.sum file in its repository.&nbsp; From there, go mod will check out the code, and check out the code&#8217;s dependencies all while doing dependency resolution in the background.&nbsp; Since git can be hosted anywhere, nailing down how many downloads a day without some kind of body providing central registration of packages like PyPI does, the best we can do is look at something like google trends for a baseline of activity.</p>



<script type="text/javascript" src="https://ssl.gstatic.com/trends_nrtr/3045_RC01/embed_loader.js"></script>
  <script type="text/javascript">
    trends.embed.renderExploreWidget("TIMESERIES", {"comparisonItem":[{"keyword":"/m/09gbxjr","geo":"US","time":"today 12-m"},{"keyword":"/m/06ff5","geo":"US","time":"today 12-m"},{"keyword":"/m/05z1_","geo":"US","time":"today 12-m"}],"category":0,"property":""}, {"exploreQuery":"geo=US&q=%2Fm%2F09gbxjr,%2Fm%2F06ff5,%2Fm%2F05z1_&date=today 12-m,today 12-m,today 12-m","guestPath":"https://trends.google.com:443/trends/embed/"});
  </script>



<p>As you can see by the graphic above, at the time of writing, Python is the dominant search in Google Trends compared to something like Golang.&nbsp; I would consider Golang a strong and growing community with projects like Kubernetes and CockroachDB along with large technology groups moving into using the stack like <a href="https://www.github.com/" data-internallinksmanager029f6b8e52c="6" title="Github" rel="nofollow noopener" target="_blank">GitHub</a> and Uber.</p>



<h3>Utility</h3>



<p>In my workflow, I am generally using Golang for 2 things; microservice apps and API middleware.</p>



<p>When I say microservice apps, I am generally not talking about something which is composed of a larger ecosystem.&nbsp; My microservice-type apps are usually tied into a Kubernetes stack.&nbsp; I had a particular challenge with <a href="https://linkerd.io/" data-internallinksmanager029f6b8e52c="3" title="Linkerd" rel="nofollow noopener" target="_blank">LinkerD</a> where I need to create a MutatingAdmissionWebhook to rewrite my HTTP(s) probes as in pod curl probes after setting my namespace to deny all.&nbsp; This was a good workaround to wrapping and rewriting many different helm charts to use curl probes instead of using standard HTTP(s) probes.</p>



<p>You can find that code <a href="https://github.com/gwagner/linkerd-convert-http-to-curl" target="_blank" rel="noopener">here</a>.&nbsp;&nbsp;</p>



<p>When doing API orchestration, I have written a few applications which will pull data from one API (or have data pushed via a webhook) into an application that may amend or transform the data before pushing it into another receiving API.&nbsp; This is particularly useful when trying to normalize data from system A to system B.&nbsp; This was particularly useful when moving from a Graphite-based metric TSDB system over to InfluxDB.&nbsp; We did not need to rewrite all of our metric collectors, we just needed to tap into the metric stream, do an on-the-fly conversion, and then output metrics to InfluxDB.</p>



<h3>Learning Resources</h3>



<ul><li><a href="https://www.udemy.com/course/go-building-devops-tools/" target="_blank" rel="noreferrer noopener">https://www.udemy.com/course/go-building-devops-tools/</a></li><li><a href="https://go.dev/learn/" target="_blank" rel="noreferrer noopener">https://go.dev/learn/</a></li><li><a href="https://www.codecademy.com/learn/learn-go" target="_blank" rel="noreferrer noopener">https://www.codecademy.com/learn/learn-go</a></li></ul>



<h2>DevOps with Ruby</h2>



<p>Because of its efficiency in DevOps, Ruby is a preferred scripting language for automating IT environments&#8217; repetitive tasks. In addition to web development, data science, and unit testing, this dynamic, interpreted programming language is used for DevOps. Ruby is also fairly simple to learn. As a result, the language has a fast-growing community of DevOps engineers. With no prior programming experience, beginners can get started with Ruby pretty quickly.&nbsp;</p>



<h3>Community</h3>



<p>Ruby is a difficult community to quantify fully simply because of how spread out it is.&nbsp; Ruby Gem can be a good baseline metric with roughly ~174,000 gems available from RubyGems.org and 111B+ (yeah, billion) downloads.&nbsp; If you look past ruby gems, the second most popular place that ruby is being utilized is with <a href="https://www.chef.io/" data-internallinksmanager029f6b8e52c="8" title="Chef">Chef</a>.&nbsp; The marketplace has roughly 4,000 cookbooks with roughly ~80,0000 maintainers</p>



<h3>Utility</h3>



<p>Ruby has some great utility when it comes to DevOps automation.&nbsp; When building out an early DevOps-focused monitoring stack, we chose Sensu Core due to its configuration-driven and scalable design.&nbsp; Most of the community-produced checks at that point were written in ruby which lent itself very well to building reusable consistent libraries that were well-tested.</p>



<p>Much like the Golang example above, I have also utilized ruby as an API middleware for doing data payload manipulations.&nbsp; Prior to Docker supporting <a href="https://docs.docker.com/config/containers/logging/json-file/" target="_blank" rel="noopener">JSON File Logging</a>, there were very long debates about what separation between log entries means between different programming languages.&nbsp; Ruby was used in an environment where I was working into tail log output from containers and based on its configuration, properly parse and package logs to be sent to centralized logging systems upstream with additional metadata.</p>



<h3>Learning Resources</h3>



<ul><li><a href="https://gorails.com/" target="_blank" rel="noreferrer noopener">https://gorails.com/</a></li><li><a href="https://www.chef.io/" target="_blank" rel="noreferrer noopener">https://www.chef.io/</a></li></ul>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Security Considerations</h2>



<p>When utilizing any code for any function whether it be DevOps or software development, you should always be concerned about security.&nbsp; Let’s say you have a 3-year-old server sitting around and its original automation code has not had any electricity run through it in the same time frame.&nbsp; That server&#8217;s automation code is probably outdated enough that there is at least some kind of CVE attached to it.&nbsp; This will be particularly easy to find if you are doing robust infrastructure scanning but will be much more obscure if you are running compiled binaries where the source code is not under some kind of routine scrutiny.&nbsp; Regardless of how you are building and running code, please make sure to clean up after yourself and avoid getting attacked by leaving a trail of outdated technology behind you.</p>



<h3>Supply Chain Attacks</h3>



<p>Supply chain attacks are all the rage these days.&nbsp; Consider the supply chain of your code dependency management system.&nbsp; Are you routinely scanning it for CVEs?&nbsp; Are you doing any kind of dynamic automated or manual testing of the code looking for vulnerabilities?&nbsp; Are you sure you can trust the source of your code dependencies?</p>



<p>DevOps code can be commonly overlooked in a supply chain attack scenario.&nbsp; Maybe you are writing a console tool to help make your life a little bit easier.&nbsp; You go ahead and pull in a few libraries from the internet to help aid in the creation of that tool like colored output.&nbsp; You also want to be really good and write automated tests as a best practice and you need help generating some data for those tests.&nbsp; Without a persistent review of code dependencies, the OSS developer/contributor of one of the dependencies that you are utilizing is tired of their <a href="https://www.bleepingcomputer.com/news/security/dev-corrupts-npm-libs-colors-and-faker-breaking-thousands-of-apps/" target="_blank" rel="noopener">work being used for free without any recognition or compensation</a> and deliberately destroys the project.&nbsp; There are also less directly malicious scenarios where the developer of a <a href="https://blog.sonatype.com/npm-project-used-by-millions-hijacked-in-supply-chain-attack" target="_blank" rel="noopener">popular package gets targeted and code is unknowingly slipped into their project</a>.</p>



<p>The lesson is this: assume that attack vectors are everywhere and ensure that you are scanning everything you can get your hands on for CVEs.&nbsp; The industry has a good focus on this now, and the question is not IF you will get compromised, but when.&nbsp; Keep yourself safe by being proactive.</p>



<h2>Conclusion</h2>



<p>As I stated at the beginning of this article, this is by no means a definitive list.&nbsp; This is a list of some of the tools that I utilized to build effective DevOps workflows and to enable the flow of delivery.&nbsp; I utilize these tools at my job along with utilizing these tools in my homelab.&nbsp; I believe that everyone could use a little bit of software development in their life.&nbsp; Python, Golang, or Ruby are really great places to start with languages because of their utility, communities, and ties to DevOps and DevOps tooling.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>What are the two major benefits of DevOps?</title>
		<link>https://www.valewood.org/major-benefits-of-devops/</link>
		
		<dc:creator><![CDATA[Greer Shepherd]]></dc:creator>
		<pubDate>Wed, 21 Sep 2022 21:16:20 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[business]]></category>
		<category><![CDATA[delivery]]></category>
		<category><![CDATA[devops]]></category>
		<guid isPermaLink="false">/?p=488</guid>

					<description><![CDATA[The first benefit of DevOps is that it enables organizations to release software faster, more reliably, and with higher quality. By breaking down the barriers between development and operations, DevOps allows teams to work together more effectively and efficiently. This&#8230;]]></description>
										<content:encoded><![CDATA[
<p>The first benefit of <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a> is that it enables organizations to release software faster, more reliably, and with higher quality. By breaking down the barriers between development and operations, DevOps allows teams to work together more effectively and efficiently. This helps companies get new features and updates into the hands of their customers more quickly.</p>



<p>The second benefit of DevOps is that it helps organizations become more agile. By automating the deployment process, DevOps makes it possible for companies to respond quickly to changes in customer demand or market conditions. This allows businesses to be more competitive and stay ahead of the curve.</p>



<p>Let&#8217;s take a look at each of these benefits in detail!</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Benefit #1: Deliver technology faster and at higher quality</h2>



<p>When your customers want more complex software products and expect you to deliver for them more quickly, the ways in which your company revolutionizes its product and service offerings will require a complete revamp. Collaboration and productivity enhancements brought about by DevOps are a big assist in meeting the innovation objectives of businesses.&nbsp;</p>



<p>The DevOps method of app development provides a company with a number of benefits, but the following five are the most important for any business that wishes to be inventive, available, and scalable. The following are those in question:</p>



<h3>Accelerate Time To Market</h3>



<p>DevOps reduces the amount of time it takes to bring a product to market, which in turn boosts business revenue. As a result of bringing together the IT and development teams to collaborate, the amount of time required to construct, test, and launch services or features is cut significantly.&nbsp;</p>



<p>The DevOps strategy enables businesses to rapidly introduce new features, rapidly improve already existing ones, and rapidly make these new or improved features available to users.</p>



<h3>Changing in Response to the Industry and Competition</h3>



<p>You have to consistently offer high-quality items if you want to succeed in an industry that is very competitive. Even if you had a fantastic idea for a business and had already started building it, that wouldn&#8217;t help you capture market share. You are in need of an improved strategy as well as a process, both of which are provided by DevOps.&nbsp;</p>



<p>The delivery of new code is made both speedy and dependable thanks to DevOps. In addition, it allows teams to construct a scalable and robust application environment while still providing users with an outstanding experience. This approach not only helps acquire the market but also thrives in a competitive market by boosting the user base and income. In other words, it is a win-win situation.</p>



<h3>Keeping the System Reliable While Preserving Its Stability</h3>



<p>Continuous testing or automated testing is something that DevOps encourages. Testing that is automated enables engineers to provide test results that are more accurate, offer fast feedback on the build, and monitor the completion of all operations. When the team searches for results, the DevOps methodology provides time savings by accelerating the availability and the entire body of work related to results in analysis on each CI/CT cycle.&nbsp;</p>



<p>This helps the team get results more quickly. The team is able to simply manage the system&#8217;s stability and dependability while also guaranteeing that the software products have excellent performance and availability.</p>



<h3>Bringing Down The Average Time To Recovery</h3>



<p>The bigger the financial effect that a corporation will have to deal with, the longer the MTTR will be. MTTR, which stands for &#8220;mean time to recovery,&#8221; is a problem that can be solved via DevOps. When a service experiences an outage, having DevOps in place may help speed up the process of repair, reaction, and recovery.&nbsp;</p>



<p>It provides assistance for monitoring mission-critical systems, which enables users to gain real-time insights on decreased performance as well as entire outages caused by events and failures. The methodology of DevOps not only makes it easier to collect precise information but also makes the incident-management system more automated. In this method, it is feasible to swiftly address the issue, which will ultimately result in a reduced MTTR.</p>



<h3>Capabilities for Providing a Better Experience to Customers</h3>



<p>DevOps approaches also place an emphasis on the one-of-a-kind characteristics of software designed for the user experience. The development of both the quality of the software and the customer experience may be sped up with the use of DevOps.&nbsp;</p>



<p>DevOps specialists monitor the customer&#8217;s point of view, plan sprints in accordance with that perspective, and test the product with the customer&#8217;s objective in mind. The team not only rapidly develops new features but also defines and enhances the whole customer journey for omnichannel.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Benefit #2: React to changing market conditions more quickly</h2>



<p>These days, businesses undergo digital transformations by adopting innovative technology and methods. Keeping up with the digital economy is a top priority, and as a result, they are putting in extra effort to improve in all areas.&nbsp;</p>



<p>They need to improve their financial performance, product quality, product speed to market, and overall company adaptability. Maintaining competitive flexibility requires effective communication, collaboration, and bug-free code, all of which may be attained through the use of Agile and DevOps processes.</p>



<h3>Create a Culture-Oriented Structure</h3>



<p>It is common practice for an organization&#8217;s culture and structure to become one and the same. Teams need to adjust their mindset in order to use DevOps successfully. To put it simply, DevOps is a rearrangement of the teams and the way they work together and communicate.&nbsp;</p>



<p>Only when individuals work well together as a team can organizations make effective use of the available resources and technology. Both the development and operations teams need each other&#8217;s support. Being able to think critically sets humans apart from machines.&nbsp;</p>



<p>Therefore, agile culture and the way humans naturally think are incompatible with the sequential waterfall paradigm. There is an urgent need to proactively address these difficulties, and the classic waterfall approach can do just that. It can also impart the benefits of the DevOps paradigm and harmonize the organizational structure.&nbsp;</p>



<p>This will boost overall collaboration and adaptability and guarantee that the company&#8217;s culture and the culture of its employees are properly melded. By focusing on the whole value chain of software delivery, DevOps is the logical next step after Agile.</p>



<h3>Streamline Techniques, Procedures, and Policies</h3>



<p>Collaboration across the organization&#8217;s development, testing, infrastructure, and IT teams is essential. Thus, the organization&#8217;s rules, procedures, and processes should reflect this. DevOps needs to reevaluate its workflow, roles, responsibilities, and methodologies if it is to attain genuine agility.&nbsp;</p>



<p>In other words, they need to have a mentality that is consistent with the agile culture, which centers on producing incremental results and accommodating change. It&#8217;s not as simple as just adding weekly scrums on top of everything else, so be prepared for some complexity.&nbsp;</p>



<p>Development and operations must collaborate with automation technologies and fully integrated processes to operate in a succession of brief efforts and genuinely execute production-ready code that can actually be delivered to clients.</p>



<h3>Streamline Rapid Growth with Minimal Discomfort</h3>



<p>Agility in DevOps is achieved by bringing together the principles of rapid development, high throughput, and careful scheduling to improve dependability and minimize disturbance.&nbsp;</p>



<p>To take advantage of Agile&#8217;s rapid iteration cycles without sacrificing quality, the DevOps model may be used to zero in on the best approach and set you up with the best agile testing tools. It helps businesses find their footing so they can effectively and efficiently adapt to changing market conditions and capitalize on emerging possibilities.</p>



<h3>Remove Organizational Barriers</h3>



<p>Organizational agility may be improved by closing the communication and collaboration gaps across departments like operations, development, and testing. By enabling continuous development, testing, and deployment with a reliable toolchain, agility may be accomplished.&nbsp;</p>



<p>There is a tight coupling between the teams, instruments, and procedures in this method. The success of the DevOps model relies on effective communication and cooperation between several functional teams, which guarantees zero barriers across multiple agile teams supported by the proper collaboration technologies.</p>



<h3>Maintain Constant Monitoring</h3>



<p>For DevOps to be effective and for a plan to be developed, feedback is essential. Having fast and accurate input is crucial to the success of a DevOps approach. Each deployment should record the basic metrics of duration, expense, and quality. Over time, this information may be examined to determine DevOps&#8217;s efficiency and adaptability and to pinpoint problem spots.</p>



<p>Culture-based indicators like team cohesion, the average time to resolve conflicts, sense of pride and ownership, and so on can be challenging to quantify. When determining the speed and efficiency of DevOps, however, these cultural criteria are crucial.&nbsp;</p>



<p>Organizational culture, methods, mentality, and toolchain should be streamlined in order to expand the DevOps model and keep it agile and relevant for providing excellent deliveries. For this reason, it is essential to employ experienced teams that can work together to concentrate on constant development and evaluation.</p>



<h2>Conclusion</h2>



<p>By focusing on the whole value chain of software delivery, DevOps is the logical next step after Agile. Additionally, the DevOps model helps businesses find their footing so they can effectively and efficiently adapt to changing market conditions and capitalize on emerging possibilities.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Do DevOps engineers need a coding background?</title>
		<link>https://www.valewood.org/do-devops-engineers-need-a-coding-background/</link>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Mon, 19 Sep 2022 21:55:03 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[coding]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[opinion]]></category>
		<category><![CDATA[software]]></category>
		<guid isPermaLink="false">/?p=326</guid>

					<description><![CDATA[The primary skill sets that DevOps engineers need are either in the system administration or software development space. Those 2 foundational skill sets will help any team build some cool solutions to complex problems. There are fringe cases where the&#8230;]]></description>
										<content:encoded><![CDATA[
<p>The primary skill sets that <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a> engineers need are either in the system administration or software development space.  Those 2 foundational skill sets will help any team build some cool solutions to complex problems.  There are fringe cases where the skillset matures outside of those two primary skill sets. Whichever skillset is lacking when making the transition from traditional delivery patterns over to a more DevOps-focused delivery pattern will need to be picked up to ensure that the team has a complete understanding of the technology stack. A system administrator will not need to become a full software developer, and a software developer will not need to become a veteran system administrator.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Role Separation</h2>



<p>First, let&#8217;s dive into role separation.  I am a firm believer in specialization in job functions.  Someone who is a jack of all trades is also generally not a master at any of them.  Individuals on the team should not be looking to be a master at every part of their delivery pipeline but they should be in a position where they are picking up adjacent skills to help backup their team members when needed.  A software developer does not need to be intimately familiar with every intricate detail of a backup solution but should know how to retrieve and restore backups when necessary.  A system administrator does not need to dive deeply into SQL query optimization, but knowing how to write and retrieve data from the database is a useful skill to help support the team.</p>



<h2>Software Development</h2>



<p>Now, this is a bit of an unfair section because I believe that the software development side of DevOps does need a coding background.  How are you going to do software development without that?</p>



<p>In all seriousness, I believe the question &#8220;Do DevOps engineers need a coding background?&#8221; can be extended into the Ops and Infrastructure space pretty easily.  Software developers should be familiar with the basic fundamentals of a data center or cloud depending on where your solution(s) is/are hosted.  If you are in a data center, become familiar with fault domains, SANs, LUNs, or anything that may impact the stability or performance of your application.  In the cloud, become familiar with the cloud&#8217;s elastic nature of volumes, instances, and services.</p>



<p>Along with the familiarity with computing platforms, it will be advantageous to also familiarize yourself with solution delivery and system configuration.  Solution delivery and delivery pipelines are essential to a good DevOps background.  In my experience, most developers are really good at utilizing their ecosystems to compile a binary or build out a package.  Aside from SFTPing that package out to a server and bouncing a service the idea of automated blue/green solution delivery flow with configuration management, rollbacks,  database updates, monitoring changes, etc. is not the norm.  </p>



<p>You SFTPers out there know who you are, don&#8217;t try to deny it.</p>



<p>The primary driver behind configuration management is trying to hit the gold standard of immutable infrastructure.  While application code is being perpetually updated and changed, servers should be treated like cattle instead of pets.  We should be able to easily destroy and fully rebuild a server and deploy the newest version of the application on top of it.  This helps keep things clean and up to date.</p>



<h2>System Administrators</h2>



<p>As system administrators make the transition from the GUI to doing DevOps, they will be faced with many challenges where a coding background can really help out.  </p>



<p>DevOps is all about automating the flow of delivery through resilient pipelines to increase quality.  To do this, most of your work is going to be through scripts or tools like <a href="https://www.chef.io/" data-internallinksmanager029f6b8e52c="8" title="Chef">Chef</a>, Terraform, <a href="https://puppet.com/" data-internallinksmanager029f6b8e52c="9" title="Puppet">Puppet</a>, CloudFormation, etc.  Composing individual scripts for individual tasks is a good place to start, but will quickly become overwhelming if you are not embracing a more generated approach.  </p>



<p>Now, all teams are going to be set up a bit differently, but a common thread across all of them will be the scale of technology becoming overwhelming at some point.  One day you may be looking at fifteen servers/services and the next day your product explodes in popularity and you are dealing with thousands of servers/services.  Take a step back and ask yourself how you can use business logic to generate your infrastructure, monitoring, configurations, backups solutions, etc.  This approach will make something that feels unmanageable and makes it manageable again.</p>



<h2>Conclusion</h2>



<p>Do DevOps engineers need a coding background?  My perspective is, that it wouldn&#8217;t hurt.  Diving into software development patterns and extending them into the DevOps delivery space allows for greater consistency, along with the ability to scale to meet demand much more quickly without feeling overwhelmed.  I don&#8217;t think that software developers need to become the best systems administrators ever created.  I don&#8217;t think that systems administrators need to become the greatest software developers ever created.  I do think that everyone in technology could benefit from a bit of exposure to spaces outside of their primary responsibilities because it lends itself well to increasing quality and flexibility while delivering solutions.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>What essential DevOps tools should you be using today?</title>
		<link>https://www.valewood.org/essential-devops-tools/</link>
					<comments>https://www.valewood.org/essential-devops-tools/#respond</comments>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Sun, 11 Sep 2022 17:03:41 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[sdlc]]></category>
		<category><![CDATA[tools]]></category>
		<guid isPermaLink="false">/?p=5</guid>

					<description><![CDATA[The goal of any DevOps tool should be to help your team communicate more effectively, automate manual tasks, and track the progress of your projects. With the right tools, you can significantly speed up your development process and produce better&#8230;]]></description>
										<content:encoded><![CDATA[
<p>The goal of any <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a> tool should be to help your team communicate more effectively, automate manual tasks, and track the progress of your projects. With the right tools, you can significantly speed up your development process and produce better results. In this post, you’ll find a list of the most essential DevOps tools and advice on how to choose the right ones for your team.</p>



<h2><strong>Build Tools</strong></h2>



<p>Build tools are an important cornerstone for any kind of DevOps workflow. Just choosing one without doing an evaluation can mean the difference between success and failure in a lot of circumstances. The build tooling must jive with the team and accomplish producing the CI/CD processes which the team expects in the way they expect them to be run. Think of them as task runners with a GUI, but each task runner has its own flare. Below is a list of tools that are widely used and could fit the bill for your next project.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h3>Jenkins</h3>



<p>If you have spent any time in the software space, or have done any googling around building software, Jenkins is sure to be the first thing that pops up. Jenkins is an open-source automation tool used for continuous integration and continuous delivery (CI/CD). Companies use it to automate the software development process, build and test their code, and deploy their applications. Jenkins is a highly configurable tool that allows you to choose from a large range of plugins. These plugins allow you to integrate Jenkins with other tools such as Docker Hub, JIRA, and others. Jenkins can be used for DevOps to automate the software delivery process, deploy apps, and manage infrastructure.</p>



<h3>Atlassian Bamboo</h3>



<p>Atlassian Bamboo is a platform for building and managing builds and deployments of software. It is generally utilized due to its tie-ins with other Atlassian products such as Jira and Confluence giving you an entire ecosystem out of the box. It is a great option if you are working in a team and want to set up a standardized process for building your code. Bamboo allows you to set up different stages of your workflow, each with its own set of tasks. This way, you can create a dev stage where your team has access to the latest version of the code and works directly from it, a test stage where your team can run tests on the latest version of the code and a production stage to deploy the code once it has been tested. As a rule of thumb, if you are working in a team that is already entrenched in the Atlassian ecosystem, go for Bamboo.</p>



<h3>Drone CI</h3>



<p>Drone bills itself as a &#8220;Self Service Continuous Integration System&#8221;, but I think you can really view any of the tools listed under build as exactly that. If you are looking for the more modern cool kid on the block, Drone CI is probably going to be a pretty good choice. Drone CI is natively built around Docker and the container ecosystem. This makes building modern applications more intuitive for individuals who are accustomed to the container ecosystem already. Drone CI also supports other types of containers, such as rkt. For developers who are not as familiar with Docker, Drone CI does have a user interface that allows you to manually configure a build environment. Drone also has a plug-in architecture, which means that you can also extend Drone’s capabilities with your own plug-ins, allowing you to configure a custom build environment as well.</p>



<h3>Travis CI</h3>



<p>Travis CI is a bit of a unique take amongst its competitors listed above. Travis CI is not a service you would normally go and locally install in your data center. Its origins are built under the idea that building environments should be ephemeral, cheap, easy, and defined via software. Their service allows you to create a new build environment by just pushing code to your <a href="https://www.github.com/" data-internallinksmanager029f6b8e52c="6" title="Github" rel="nofollow noopener" target="_blank">GitHub</a> repository. The great thing about this is that it allows you to create any type of environment you want. In the case of Travis CI, they allow you to build your environment in a way that is open source and completely controlled by you.</p>



<h3>GitHub Actions</h3>



<p>GitHub Actions is a new entrant to the build and deploy space, and frankly, the next logical step in GitHub&#8217;s journey of code hosting. GitHub has become the de-facto standard for hosting code, and Actions takes it a step further by allowing you to programmatically trigger a series of actions on your code, such as building, testing, publishing, and deploying it. Actions is a game changer as it allows anyone to create their own automated workflow without the need for any additional software. For example, let’s say you want to deploy your code to your staging environment every time you push a new commit to your master branch. You can now easily set up an action that listens for new commits on the master branch, checks out the code, kicks off a build process, and then deploys the code to your staging environment.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>In this space, I am a fan of the tool that gets the job done. I don&#8217;t have any particular allegiances because build tools are just dumb task runners. Maybe a UI speaks to you more, or a set of tools plugs into an ecosystem more seamlessly than another tool. Either way, do a bit of evaluation and make sure you are not painting yourself into a corner, and you will be just fine with any of these tools. Sign up for free trials, do a bit of exploring, and if you have questions, there is a vibrant community of people who are happy to help! Stay tuned to blog posts, newsletters and social media to stay up to date on new features and helpful tips and tricks!</p>



<h2><strong>Server Configuration Management</strong></h2>



<p>Below, <a href="https://puppet.com/" data-internallinksmanager029f6b8e52c="9" title="Puppet">Puppet</a> and <a href="https://www.chef.io/" data-internallinksmanager029f6b8e52c="8" title="Chef">Chef</a>, are the two 5000-pound gorillas in the room when it comes to configuration management DevOps tools. Other competitors exist in the space, but I would argue always live on the fringes and are not really taking any market share away from these two primary options any time soon. Some would argue that <a href="https://www.ansible.com/" data-internallinksmanager029f6b8e52c="7" title="Ansible">Ansible</a> should be in this category as well, but I would argue that Ansible is a task orchestrator and NOT a configuration management tool. Give Ansible tasks, it orchestrates tasks, and when it completes someone will need to write more code to determine if the task was executed correctly. In my eyes, DSCM-level validation of completion is a core feature that a configuration management system should have out of the box, otherwise, it is a task orchestrator masquerading around to be something like a configuration management DevOps tool. Don&#8217;t get me wrong, there is still a spot in my heart for Ansible, just not under configuration management.</p>



<h3>Puppet </h3>



<p>Puppet is an open-source tool for managing infrastructure as code (IaC). It’s often used for configuration management, service deployment, and continuous delivery. Puppet works by installing agents on different system types and installing the Puppet server on one or more machines. The Puppet server manages the agents to configure the systems based on user-defined policies. It can be used with DevOps to manage configuration policies, provision and configure infrastructure, and automate deployment. When using Puppet myself, I normally do not connect Puppet back to a Puppet master. I run puppet headless so that my idempotent builds can be deployed and triggered at will. This also helps avoid some of the licensing costs of Puppet. As of the writing of this post, their pricing is also hidden behind a contact wall. This generally means: &#8220;If you have to ask, you probably can&#8217;t afford it&#8221;.</p>



<h3>Chef</h3>



<p>Chef is an open-source tool for managing infrastructure as code (IaC). It’s often used for configuration management, service deployment, and continuous delivery. Chef works by installing agents on different system types and installing the Chef server on one or more machines. The Chef server manages the agents to configure the systems based on user-defined policies. It can be used with DevOps to manage configuration policies, provision and configure infrastructure, and automate deployment. When using Chef myself, I normally do not connect Chef back to a Chef master. I run puppet headless so that my idempotent builds can be deployed and triggered at will. This also helps avoid some of the licensing costs of Chef.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>As you can see, the descriptions of the tools are nearly identical. The primary difference between these two tools is going to be the community supporting package availability, price, and their specific DSL. Chef is primarily Ruby driven which gives you a TON of flexibility when you need it by diving into the Ruby space. This is an antipattern so use it sparingly, but it can be helpful in a pinch. I would also argue that the Chef community is currently much stronger than the Puppet community having many more packages developed and maintained by the community. In my career, I started with Puppet and converted to Chef simply for that fact.</p>



<h2><strong>Infrastucture Configuration Management</strong></h2>



<p>In this post, I am going to be focusing on <a href="https://aws.amazon.com/" data-internallinksmanager029f6b8e52c="14" title="AWS" rel="nofollow noopener" target="_blank">AWS</a> and Azure as the primary examples of IaC CM tools. I am explicitly ignoring GCP, <a href="https://www.digitalocean.com/" data-internallinksmanager029f6b8e52c="5" title="DigialOcean" rel="nofollow noopener" target="_blank">DigitalOcean</a>, etc. because every cloud vendor has its own APIs, its own tool sets, and its own concepts which are really all born from what AWS and Azure have already pioneered.  If you are interested in the most marketable DevOps tools focusing on infrastructure configuration management, then these are the tools I would focus on first.</p>



<h3>AWS CloudFormation</h3>



<p>AWS CloudFormation is a native toolset provided by AWS which is utilized to configure their cloud platform. It enables you to configure your cloud infrastructure and also create templates for future usage. These templates can be used to create infrastructure as code, which is a best practice in terms of cloud adoption. CloudFormation provides you with a lot of flexibility as compared to other tools, but it is not easy to start with.</p>



<h3>Azure ARM Templates</h3>



<p>Using an ARM template, you can declaratively create and deploy Azure infrastructure, including virtual machines, networks, storage systems, and any other resources you require. The template simply describes what you want to happen, and Azure takes care of the details. You can also use templates to generate code or scripts to create or customize resources. Versioning: You can keep track of changes to your templates by keeping them in source control, just like you would any other code. You can also use templates to generate reports, giving you an easy way to track changes to your infrastructure. Reusability: You can create a library of templates to use in different scenarios.</p>



<h3>Terraform</h3>



<p>Terraform is a cross-cloud IaC tool produced by HasiCorp. They take a unique view of IaC where components that span across multiple clouds should be abstracted out for future reuse. Terraform is also a unique tool in that its open source, but has a paid enterprise version with additional features. Terraform is a great fit for enterprise environments where you want to maintain strict version control of your cloud infrastructure, have strict regulatory requirements, or have a dedicated team managing the infrastructure where you want to streamline your process with a tool that can enforce policies across the organization.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>I really don&#8217;t have a right or wrong answer for this space. I do believe that if you have a need to get into the deepest nooks and crannies of a cloud hosting vendor, using native tooling (CloudFormation and ARM Templates) will always beat what Terraform has to offer. If you are looking to be a bit more functional cross-cloud by providing an interface for your organization to consume, Terraform is probably a better option.</p>



<h2><strong>Monitoring and Observability</strong></h2>



<p>I believe that there is no right answer to monitoring and observability as long as the answer doesn&#8217;t work for the team that needs to receive the alerts. If you are using a 24&#215;7 on-call system like OpsGenie, and your technologists refuse to install the application on their devices to get notified, it is probably the wrong way to go about ensuring someone is alerted to issues. The tools listed below range from out-of-the-box to highly customizable tools. Each approach has its advantages and disadvantages. If you are going to go with highly customizable and integrate that directly into your pipelines, then the team must be on board with the idea of additional maintenance in code space rather than the GUI space, and vice-versa for the out-of-the-box tools. As long as you and your team agree on the strong fundamentals of &#8220;99.9% of the time, get an alert that something is wrong before someone else notices and reports it&#8221;, then you at least have a good foundation to start selecting monitoring from.</p>



<h3>LogicMonitor</h3>



<p>From physical hardware to software applications, to virtual hosts, to network devices, to cloud infrastructure — LogicMonitor monitors it all. LogicMonitor is able to monitor virtual environments with its application monitoring capabilities. It can also monitor physical environments with its physical monitoring capabilities. With LogicMonitor’s comprehensive monitoring capabilities, it’s no wonder that it’s the monitoring software of choice for thousands of organizations worldwide.</p>



<h3>Sensu </h3>



<p>It works with any monitoring tool, like Graphite, Collectd, Elastic, and more. It can also receive data from other loggers, like statsd, in real-time. Sensu Go can collect data from virtually any source, maintain it in a data store for analysis, and send it to any output, including email, mobile push notifications, or synchronous or asynchronous webhooks. It is open source, flexible, and extensible with a wide range of configuration options.</p>



<h3>Prometheus</h3>



<p><a href="https://prometheus.io/" data-internallinksmanager029f6b8e52c="2" title="Prometheus" rel="nofollow noopener" target="_blank">Prometheus</a> is a popular open-source monitoring system for metrics, logs, and events. It enables querying, graphing, and alerting on time-series data. It collects metrics from a variety of sources, including systems and applications, and stores the metrics data in a data store. The metrics data is then made available for analysis via a variety of tools. Prometheus has a flexible architecture and can be deployed on-prem or in the cloud. It is highly scalable and can support metrics from any type of application. It is widely used by enterprises to monitor their production systems.</p>



<h2><strong>Task Runners / Orchestration Tools</strong></h2>



<p>I am only putting one tool in this section because I believe that there is only one tool worth talking about. That DevOps tool is Ansible.  Ansible is like a swiss army knife of task orchestration and your ability to hop in and out of specific contexts is unparalleled.</p>



<h3>Ansible</h3>



<p>Ansible is a tool for automating tasks across multiple devices &#8211; from physical hosts to virtual machines and even cloud providers. It allows you to programmatically automate tasks and workflows, and it’s the most widely adopted open-source automation tool in the world. In fact, according to the 2017 State Of Configuration Management Survey, Ansible is the most widely used configuration management tool in enterprises. Unlike other tools, Ansible requires very little upfront investment — you can get started with a free download. Additionally, there are many ways to scale Ansible beyond a single node, including cloud services like AWS, Microsoft Azure, or Google Cloud Platform.</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<p>If you are looking to orchestrate events across multiple machines, services, or clouds; I honestly do not know why you would choose anything else.  I have used ansible to manage 1000+ machines in a data center orchestrating events across servers, services, clouds, and physical equipment all while making the intentions of the orchestration very clear to future engineers.</p>



<h2><strong>Conclusion</strong></h2>



<p>DevOps is a set of practices that combines software development and operations to shorten the development life cycle and provide continuous delivery and faster time to market. It’s a culture shift that requires collaboration between Development and Operations teams. The tools used in DevOps can be customized to meet the unique needs of your organization. These tools can automate the software delivery process, provision and configure infrastructure, and deploy applications.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.valewood.org/essential-devops-tools/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Why are CI/CD Pipelines Part of DevOps?</title>
		<link>https://www.valewood.org/why-are-ci-cd-pipelines-part-of-devops/</link>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Mon, 05 Sep 2022 16:47:35 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[sdlc]]></category>
		<category><![CDATA[software]]></category>
		<guid isPermaLink="false">/?p=312</guid>

					<description><![CDATA[CI/CD pipelines are a key part of the DevOps process. They allow you to automate the process of getting your code from development to production through CI/CD. CI/CD stands for Continuous Integration and Continuous Deployment. This helps to speed up&#8230;]]></description>
										<content:encoded><![CDATA[
<p>CI/CD pipelines are a key part of the <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a> process. They allow you to automate the process of getting your code from development to production through CI/CD.  CI/CD stands for Continuous Integration and Continuous Deployment. This helps to speed up the process and ensure that your code is always in a ready-to-deploy state. There are a number of different tools that you can use for creating DevOps pipelines. You can think of it like an assembly line where technology components and quality checks and gates are passed on the way to production. A more apt analogy would be the assembly line in the manufacturing industry where physical products are made. Think of a car made of parts going down a conveyor belt to different stations where it is assembled. A DevOps pipeline is kind of like that. But instead of cars, DevOps pipelines are for software and applications. And instead of physical parts, they are for software components like source code and automated scripts.</p>



<p>There are several key parts of the assembly line that must be considered. The key parts of a successful DevOps pipeline are all continuous; integration, delivery, testing, monitoring, feedback, and operations.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>The DevOps <s>Assembly Line</s> CI/CD Pipeline</h2>



<h3>Continuous Integration</h3>



<p>Integration is the process whereby all developers make their code changes available to other team members. This is often done using a source code repository and an automated build step. Developers, ops, qa, etc. all contribute to the same process which enhances the same product with everybody moving the same automobile down the assembly line together.</p>



<p>Most organizations have a &#8220;git&#8221; repository that holds all the source code. This can be a private repository, shared publically, or a combination of both. It is commonly referred to as a &#8220;<a href="https://www.github.com/" data-internallinksmanager029f6b8e52c="6" title="Github" rel="nofollow noopener" target="_blank">GitHub</a>&#8221; or &#8220;GitLab&#8221; repository. Utilizing feature branching strategies, build or feature flags, and a myriad of other code organization strategies; the code repository becomes the central hub for all work happening in and around the technology product.</p>



<h3>Continuous Delivery</h3>



<p>Delivery is the process whereby the integrated code changes are deployed to a test or production environment. It involves package or container creation, deployment, and feature enablement in a production environment. The overall scope of work is narrowed down from large unwieldy projects to something more complementary to a single bolt being added to a car or truck. In the physical world, those incremental steps are not only performed, but in our modern industrial assembly lines, the impact wrench which is utilized will measure and record the torque applied while the car is being assembled. Continuous delivery is no different. Code should always be ready to be deployed to production because every minor tweak, change, or enhancement is fully tested as it is added to the code repository.</p>



<h3>Continuous Testing</h3>



<p>Testing is the stage where the output of delivery is tested to ensure that it performs as expected in a testing environment. The gold standard here is to ensure that 100% of your application is fully tested on every single commit. Full coverage testing is often used when developing in an agile or Scrum environment, where developers will have small, incremental changes to the code. When modernizing an application where automated testing was not done from the start, you may see much lower percentages as you get your application up to spec. This is OK! Make sure testing is a focus and a breakpoint is added where it no longer becomes acceptable to not test changes.</p>



<h3>Continuous Monitoring and Feedback</h3>



<p>I am going to let you in on a secret, &#8220;humans are not robots&#8221;. This means that we are going to make mistakes. It is just part of the job. Mistakes should always be an acceptable part of the work done in the technology sector. Here is what should really drive people crazy instead of mistakes, not knowing when mistakes were made or when something fails. So, what can we do about it? Simply put, build some observability!</p>



<p>Observability, a common NFR in technology, is the concept that not only should your technology have some up/down state monitoring behind it, but you should be able to also get good telemetry around the full set of business processes as well. Looking at some basic observability items such as activity counters, page performance and event timing, errors, failures, success, etc. you can build a set of observability around key metrics which tell you can line up to show the differences between how you expect your application to be performing versus the reality of how it is performing.</p>



<p>When it comes to Continous Feedback, now that we are in this panacea of speedy and rigorously tested application deployments, we can get this observability feedback into the hands of our DevOps teams to ensure that appropriate changes are put into the application. Without good early feedback supported by a mountain of data, the team will be left guessing. Let’s be honest, everyone on the team needs this feedback. The DevOps team doesn’t need to know everything. They do need to know enough to assess whether or not the changes they make to the application are safe and meet business requirements.</p>



<p>Regardless of whether you’re building a standalone product or a company, the key takeaway here is that you want to be thinking about observability in terms of the business process as a whole paired directly with technology. A car company is not going to set out to produce the next top-of-the-line pickup truck and end up with a Pontiac Aztec unless something goes very wrong while nobody is looking.</p>



<h3>Continuous Operations</h3>



<p>Everyone is responsible for operations. Product Managers, Developers, CEOs, Finance and Accounting, and Operations; everybody shares some role in the responsibility. When it comes to DevOps the role of operations is filtered directly into the central workstreams of the team. When an outage occurs, RCAs and post-mortems do not stop at a ceremonial activity. They are carried through to completion with real changes being put in place. Utilizing all of the aforementioned steps of the assembly line, the DevOps team is able to more quickly remediate issues that either show up due to mistakes or show up due to the growth of a system over time.</p>



<p>One of the core things to remember about operations is that technology does not age well. The longer something is running in the wild, the frailer it will get. Think about it this way; if you never service your car, the engine will start to overheat, your tires will start to go bald, and you may run out of blinker fluid. As time goes on, the car gets more and more unreliable. This is true of any technology as well. Operations needs to be accessible to everyone, and it needs to be prioritized in a way that allows for a healthy mix of feature functionality and operations to coexist.</p>



<h2>Conclusion</h2>



<p>In conclusion, DevOps Pipelines can be easily attributed to an assembly line of technology. Through a set of core principles, like always being ready for production, along with integrated technology which promotes testing, monitoring, feedback, and observability the pipeline approach enables organizations to achieve rapid time-to-market and continuous delivery of software products and services (and they can enjoy the velocity and quality benefits at a fraction of the cost).</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>How DevOps Can Improve Your Technology Stack</title>
		<link>https://www.valewood.org/how-devops-can-improve-your-technology-stack/</link>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Sun, 04 Sep 2022 18:50:18 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[software]]></category>
		<guid isPermaLink="false">/?p=304</guid>

					<description><![CDATA[DevOps is a set of practices that combines software development and operations to improve the speed, quality, and reliability of software delivery. DevOps is about collaboration and communication between development and operations teams. In many instances, these 2 teams are&#8230;]]></description>
										<content:encoded><![CDATA[
<p><a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a> is a set of practices that combines software development and operations to improve the speed, quality, and reliability of software delivery. DevOps is about collaboration and communication between development and operations teams.  In many instances, these 2 teams are combined into one providing a shared focus and shared set of responsibilities.  The team becomes responsible for the entire lifecycle surrounding a set of technology.  The strategic themes for this team center around automating the software delivery process so that software can be delivered faster, with fewer errors. DevOps is a relatively new concept, but it’s quickly gaining popularity because it’s an effective way to improve the technology stack. In this article, we’ll explore how DevOps can improve your technology stack.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>What is DevOps?</h2>



<p>DevOps is a software development methodology that seeks to automate the software delivery process. The goal of DevOps is to improve the speed, quality, and reliability of software delivery by integrating software development and operations.  This shared responsibility builds on a set of common goals which may have caused tension in the past.  Development teams have been traditionally focused on shipping new features while handing those features off to the operations team to run them.  The operations team was then responsible for running something they did not build and may have had additional considerations to improve overall quality.</p>



<p>Combining Development and Operations together nets out a single team that can view the entire landscape of technology improving visibility which improves decision-making.  There is a misnomer out there in the industry which drives me bonkers, and that is the idea of a &#8220;Full Stack Engineer&#8221;.  I don&#8217;t actually know what that is, do you?  My best guess is that a hiring manager needs A LOT of skills and doesn&#8217;t have the budget to pay for them.  Instead, by building a &#8220;Full Stack Team&#8221; someone could yield all of the benefits of a &#8220;Full Stack Engineer&#8221; without overworking any individual contributor. </p>



<p>By employing a more DevOps-focused delivery methodology, businesses can respond more quickly to new market opportunities, deliver products and services with less downtime, and provide more reliable customer experiences.  Everything you need to move large rocks uphill exists inside of a single team with a singular focus.</p>



<h2>The Benefits of DevOps</h2>



<p>If you’re wondering why you should invest time and resources in implementing a DevOps strategy, here are some of the key benefits of DevOps:</p>



<ul><li>Increased speed and agility &#8211; DevOps can help businesses respond more quickly to new market opportunities.  DevOps enables businesses to adapt and respond to changes quickly, while also meeting their service-level agreements (SLAs). It also enables continuous deployment, which means businesses can release software more often.  By releasing more frequently, you’re able to respond quickly when the market changes.</li><li>Higher quality &#8211; DevOps is often associated with implementing automation. By using automation to build, test, and deploy applications, you can catch bugs and other quality issues before they make their way into production. Automation also allows you to test the quality of your application more frequently, which enhances your ability to identify and fix quality issues as soon as possible.</li><li>Better collaboration &#8211; DevOps is a very collaborative approach to software development. When everyone works together to solve problems, issues are identified and resolved more quickly. Plus, collaboration helps teams solve more complex problems, which leads to higher-quality work and more innovative products.</li><li>Reducing risk &#8211; DevOps helps teams identify and mitigate risks early in the software delivery chain, which reduces overall risk. If you’re able to identify risks related to security, architecture, or other factors, you can address them quickly and effectively. This helps your organization avoid costly problems, such as data breaches or system failures.</li><li>More reliable customer experiences &#8211; When customers use your product or service, they expect it to work. By integrating development and operations, DevOps helps teams identify and resolve issues quickly, which means fewer disruptions and fewer outages.</li></ul>



<h2>Implementing DevOps in Your Organization</h2>



<p>If you’re wondering how to get started with DevOps, there are three steps you can take to get your organization on the path toward success.</p>



<ul><li>Build a strong culture of trust &#8211; Successful DevOps implementations depend heavily on trust. Your organization needs to trust that developers and operations personnel will do what’s best for the company. Operations staff needs to trust that developers have the skills and knowledge to deliver what’s needed. So, when you’re first implementing DevOps, focus on building a culture of trust.</li><li>Invest in automation &#8211; Automation is critical to successful DevOps implementations because it enables organizations to release more frequently without increasing risk. Automating application builds, deployments, and tests allows teams to complete tasks more quickly and with fewer errors. Automating environments, such-as infrastructure and application configuration, also helps you avoid hand-crafted environments.</li><li>Create a single source of truth &#8211; A single source of truth refers to a central location where all critical information is stored. It’s critical that all members of the organization have access to this information. By creating a single source of truth, you can create a culture of collaboration and knowledge sharing that’s crucial to DevOps implementation success.</li></ul>



<h2>Conclusion</h2>



<p>As you’ve seen, DevOps is a software development methodology that seeks to automate the software delivery process. The goal of DevOps is to improve the speed, quality, and reliability of software delivery by integrating software development and operations. DevOps has several benefits, including increased speed and agility, increased quality, better collaboration, reduced risk, and more reliable customer experiences. To implement DevOps in your organization, you first need to build a strong culture of trust, invest in automation, and create a single source of truth.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>DevOps Roll-up: August</title>
		<link>https://www.valewood.org/devops-roll-up-august/</link>
					<comments>https://www.valewood.org/devops-roll-up-august/#respond</comments>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Wed, 31 Aug 2022 17:00:00 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[Roll-up]]></category>
		<category><![CDATA[day2ops]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[kubernetes]]></category>
		<guid isPermaLink="false">/?p=52</guid>

					<description><![CDATA[Below is a list of DevOps articles/sites that I discovered over the past month and found interesting. DevOps Roadmap First is a link to a DevOps roadmap. This is a more technological than a philosophical view of what kinds of&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Below is a list of <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a> articles/sites that I discovered over the past month and found interesting.</p>



<h2>DevOps Roadmap</h2>



<p>First is a link to a DevOps roadmap.  This is a more technological than a philosophical view of what kinds of skills can be acquired in order to perform DevOps activities when on a team that does delivery via DevOps practices.</p>



<p><a href="https://roadmap.sh/devops" target="_blank" rel="noreferrer noopener">https://roadmap.sh/devops</a></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2>Diagramming and Documentation</h2>



<p>Next is a programmatic diagramming tool that allows you to set up diagrams for your implementations via Python.  One of the most difficult parts of any progressive technology implementation is ensuring that your materials remain up to date and available to new and existing team members.  By putting this information into the code repository, and by allowing those artifacts to become part of the build pipeline, you can get much closer to that idealistic view of well-developed and well-run technology by closing this particular </p>



<p><a href="https://diagrams.mingrammer.com/" target="_blank" rel="noopener">https://diagrams.mingrammer.com/</a></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2>DoorDash Outage</h2>



<p>Next is an article that describes a postmortem from a <a href="https://kubernetes.io/" data-internallinksmanager029f6b8e52c="4" title="Kubernetes" rel="nofollow noopener" target="_blank">Kubernetes</a> outage at DoorDash.  This article helps illustrate the importance of not only reading the docs but also expresses the importance of testing your various failure scenarios to ensure that your entire team understands the various failure mechanisms and their impacts on a normally operating system.</p>



<p><a href="https://doordash.engineering/2022/08/09/how-to-handle-kubernetes-health-checks/" target="_blank" rel="noopener">https://doordash.engineering/2022/08/09/how-to-handle-kubernetes-health-checks/</a></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2>Kubernetes Storage</h2>



<p>Sticking with Kubernetes (and any flavor of Kubernetes you may be interested in); dealing with storage as part of your implementation OnPrem is a challenge.  This article does a great job of illustrating that challenge and what i means to anyone who has not yet made it to the cloud.  What I hope you take from this is, it is not impossible to accomplish and there are many solutions to this problem, but the downstream operational impacts of doing this are far broader than the initial implementation.</p>



<p><a href="https://refaktory.net/blog/posts/self-hosted-kubernetes-solving-the-storage-problem" target="_blank" rel="noopener">https://refaktory.net/blog/posts/self-hosted-kubernetes-solving-the-storage-problem</a></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>



<h2>Traffic Visualization</h2>



<p>Visualizing what is happening in your cluster can be a challenge.  I have taken the strategy of implementing <a href="https://linkerd.io/" data-internallinksmanager029f6b8e52c="3" title="Linkerd" rel="nofollow noopener" target="_blank">Linkerd</a> into my lab cluster to support both mTLS along with traffic visualization, but that is not the only way to accomplish this.  Lots of teams are familiar with <a href="https://grafana.com/" data-internallinksmanager029f6b8e52c="1" title="Grafana" rel="nofollow noopener" target="_blank">Grafana</a> as their source of information, especially with the proliferation of something like <a href="https://prometheus.io/" data-internallinksmanager029f6b8e52c="2" title="Prometheus" rel="nofollow noopener" target="_blank">Prometheus</a>.  k8spacket is a tool that helps bring a version of that visualization directly into Grafana dashboards.</p>



<p><a href="https://medium.com/@bareckidarek/tcp-packets-traffic-visualization-for-kubernetes-by-k8spacket-and-grafana-bb87cb106f30" target="_blank" rel="noopener">https://medium.com/@bareckidarek/tcp-packets-traffic-visualization-for-kubernetes-by-k8spacket-and-grafana-bb87cb106f30</a></p>



<hr class="wp-block-separator has-alpha-channel-opacity"/>
]]></content:encoded>
					
					<wfw:commentRss>https://www.valewood.org/devops-roll-up-august/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>How to Build a DevOps Pipeline Geared for Stability?</title>
		<link>https://www.valewood.org/devops-pipeline-geared-for-stability/</link>
					<comments>https://www.valewood.org/devops-pipeline-geared-for-stability/#respond</comments>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Tue, 30 Aug 2022 02:47:33 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[development]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[sdlc]]></category>
		<guid isPermaLink="false">/?p=95</guid>

					<description><![CDATA[Building a devops pipeline is easy. Wire up a few components, write some scripts, glue on some tests, and add credentials for production, and voila you are DevOps-ing!! Well&#8230; not exactly. In my experience, this is where things usually start,&#8230;]]></description>
										<content:encoded><![CDATA[
<p>Building a <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">devops</a> pipeline is easy.  Wire up a few components, write some scripts, glue on some tests, and add credentials for production, and voila you are DevOps-ing!!  Well&#8230; not exactly.  In my experience, this is where things usually start, but will quickly lead to new and additional churn in a delivery cycle which was never intended.  Sometimes that churn goes completely unrecognized simply because the thought of doing DevOps is far better than the idea of not doing DevOps.  Either way, do yourself a favor and take a step back to look into how intentional design, intentional component selection, along with care and feeding can get you into a spot where your pipelines work for you instead of you working for your pipelines.</p>



<p>In case you are wondering, &#8220;what is a pipeline in DevOps&#8221;?  A pipeline in DevOps is centered around the idea of ensuring code is continuously delivered which in turn means the business is seeing a continuous flow of value.  There are many DevOps pipeline tools on the market, but I want to take step back and discuss more of the planning and design side of things before diving directly into tooling.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2>Intentional Design</h2>



<p>Deploying Jenkins, giving it some keys, giving it a job to do, and then finally pointing at production will yield a short-term win with long-term consequences.  While I believe that most aspiring DevOps engineers will start here, more intentional design should be considered when building a pipeline.</p>



<h3>Who are the consumers of your DevOps Pipeline?</h3>



<p>Consider who is going to be consuming the pipeline that is being created.  Some organizations want manual approvals, some want automated approvals, some are a bit more cowboy and approvals are not part of the conversation.  Sometimes a QA team, project/program management, developers, executives, or the lunch lady could be consumers of your pipeline.  Consider them when designing what you will use for delivery.</p>



<h3>What are the goals of your DevOps Pipeline?</h3>



<p>Not everyone is going to agree here, but when I am doing a design, I start by conceptualizing my end state much like pointing a ship in the direction that I think I want to go.  This allows me to get more eyes on the concept that I am building toward while pulling in feedback from interested stakeholders.  On the back of that work, I will take a step back and try to understand the strategic themes and goals of the pipeline to get more broad alignment from the consumers and stakeholders.  </p>



<p>Just because someone tells you that they want something, doesn&#8217;t mean that you heard them correctly or they fully understood what they are asking for.  Try to take time and dissect their request and either align it to your design walking the requestor through how your solution solves their needs, or reframe your specific thinking of the problem to accommodate their request.</p>



<h3>Is there a logical flow you can follow?</h3>



<p>I like to map out my process as illustrated below.</p>


<div class="wp-block-image">
<figure class="aligncenter size-large"><img width="1024" height="204" src="https://www.valewood.org/wp-content/uploads/2022/08/devops-pipeline-flowchart-1024x204.png" alt="DevOps Pipeline Flowchart" class="wp-image-273" srcset="/wp-content/uploads/2022/08/devops-pipeline-flowchart-1024x204.png 1024w, /wp-content/uploads/2022/08/devops-pipeline-flowchart-300x60.png 300w, /wp-content/uploads/2022/08/devops-pipeline-flowchart-768x153.png 768w, /wp-content/uploads/2022/08/devops-pipeline-flowchart-1536x306.png 1536w, /wp-content/uploads/2022/08/devops-pipeline-flowchart-2048x409.png 2048w, /wp-content/uploads/2022/08/devops-pipeline-flowchart-1920x383.png 1920w, /wp-content/uploads/2022/08/devops-pipeline-flowchart-1170x233.png 1170w, /wp-content/uploads/2022/08/devops-pipeline-flowchart-585x117.png 585w" sizes="(max-width: 1024px) 100vw, 1024px" /></figure></div>


<p>By taking the time to understand the ins and outs of your pipeline, the decision tree that gets created, necessary supplemental steps, and points of failure you can design a logical flow that works across many different arenas.  A single logical flow may work well to get code into a development environment, but do you really need to redo each and every step to move code to the next environment or can you adjust your logical flow to be less cumbersome?</p>



<h2>Intentional Component Selection</h2>



<p>Normally I am not a fan of Jenkins.  I believe that it is allowing for quick and dirty instances of automation to be put out into the market in a way that does not promote stability.  Don&#8217;t get me wrong, Jenkins is an interesting tool if you look at it as a dumb task runner, but is a pretty poor tool if you are really taking automation seriously.  Intentional component selection is a topic we should spend some time on due to the technology strongholds that are out in the market today.</p>



<h3>So, who are the consumers of your DevOps Pipeline?</h3>



<p>No no, this section is not a duplicate.  When choosing your components, you need to consider your consumers.  Luckily, most of your consumers in this space are going to be technology focused so we can hopefully ignore non-technical actors for the most part.  If your team is primarily composed of PHP developers, it is probably not a good idea to try and pull in something which is well outside of the PHP ecosystem.  Stick with tools that are similar to other existing tools in your environment.</p>



<p>Providing good feedback to your engineers is also something you should pay attention to.  If your pipeline does happen to break for one reason or another, and the error messages are cryptic, you will end up in the &#8220;You built it you own it&#8221; paradigm.  There is no democratization of the pipeline out to consumers to facilitate care and feeding, which we will discuss later.  A good DevOps pipeline should support your engineers, not be an exercise in decoding the enigma machine.</p>



<h3>Perfection is the enemy of progress!</h3>



<p>Component selections can be a long drawn-out process.  Spending too much time trying to decide will lead to the projects around you getting too far ahead of your efforts causing a lot of undo stress and rework.  It is better to pick something and prove why it won&#8217;t work over time instead of trying to find the magical purple unicorn which solves 200% of use cases.</p>



<h3>Clearly defined single responsibilities!</h3>



<p>To fight perfection shutting down progress, try to limit your components to single responsibilities.  You can really apply <a href="https://www.digitalocean.com/community/conceptual_articles/s-o-l-i-d-the-first-five-principles-of-object-oriented-design" target="_blank" rel="noopener">SOLID OOD</a> can really be applied anywhere in technology.  By limiting your components to a single responsibility, you can set up your components as interfaces with each other.  Component 1 expects this input and provides this output.  The magic between input and output can be as complex as you want it to be as long as the inputs and outputs are consistent.  You can then feed the outputs of component 1 into the inputs of component 2.  Continue this pattern for N components.</p>



<p>What you end up with is a set of &#8220;jobs&#8221; which facilitate specific tasks.  Each of these jobs is testable, improvable, observable, and most importantly; your jobs are understandable!  If you want to break free from &#8220;you built it, you own it&#8221; then everything in your stack should be something that can be handed off to another flesh and blood human being who can pick up your work and run with it.</p>



<h2>Care and Feeding</h2>


<div class="wp-block-image">
<figure class="alignright size-medium is-resized"><img src="https://www.valewood.org/wp-content/uploads/2022/08/amanda-lim-n0s7y7Nr2A-unsplash-200x300.jpg" alt="Care and Feeding (Not a real picture of the Ron Popeil Rotisserie)" class="wp-image-278" width="133" height="198" srcset="/wp-content/uploads/2022/08/amanda-lim-n0s7y7Nr2A-unsplash-683x1024.jpg 683w, /wp-content/uploads/2022/08/amanda-lim-n0s7y7Nr2A-unsplash-scaled.jpg 1707w" sizes="(max-width: 133px) 100vw, 133px" /></figure></div>


<p>Any technology anywhere will need care and feeding.  There is nothing that can be built and just runs like a perpetual motion machine.  You will need to consider the care and feeding of your DevOps pipeline.  Some of the care and feeding will be simple.  Password rotations, library updates, edge case fixes, etc. can all be accomplished as part of the daily flow of work.  More complex care and feeding such as component replacement, break glass in case of emergency, security hardening, etc. will need to be planned into your delivery lifecycle planning.  </p>



<p>As a quick side tangent, when the term care and feeding comes up as part of normal conversation, does anyone else hear Ron Popeil and his overly excited audience say &#8220;Set it and forget it&#8221;?</p>



<h2>Conclusion</h2>



<p>As you can see, a stable DevOps pipeline will consist of many steps which all feed off of each other ending up in a GitOps-style deployment pipeline.  I believe that the magic in any well-developed, well-set-up DevOps pipeline has a foundation in having a clear definition of your intentions, and intentional components which provide specific functionality, and each component needs attention + care and feeding like any other technology stack that is being supported.  Not every pipeline needs to be as complex, or overly simplistic depending on your frame of reference since there is no one size fits all solution to robust delivery.  Start small, but be intentional and you too can have a DevOps Pipeline Geared for Stability!</p>
]]></content:encoded>
					
					<wfw:commentRss>https://www.valewood.org/devops-pipeline-geared-for-stability/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>DevOps Deployments: Fast, Easy, and Fun!</title>
		<link>https://www.valewood.org/devops-deployments-fast-easy-and-fun/</link>
					<comments>https://www.valewood.org/devops-deployments-fast-easy-and-fun/#respond</comments>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Sun, 21 Aug 2022 19:33:46 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[devops]]></category>
		<category><![CDATA[gitops]]></category>
		<category><![CDATA[nfr]]></category>
		<category><![CDATA[sdlc]]></category>
		<guid isPermaLink="false">/?p=48</guid>

					<description><![CDATA[One of the core fundamentals of DevOps is to ensure that deployments are fully automated. The technology stack that you are supporting should be fully production ready at all times. This means that DevOps does not stop at IaC automation.&#8230;]]></description>
										<content:encoded><![CDATA[
<div class="wp-container-1 wp-block-group"><div class="wp-block-group__inner-container">
<p>One of the core fundamentals of <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a> is to ensure that deployments are fully automated.  The technology stack that you are supporting should be fully production ready at all times. This means that DevOps does not stop at IaC automation.  The full SDLC needs to be constructed in such a way that it enables more of a GitOps model rather than a series of disconnected pieces.</p>



<p>Let&#8217;s face it; unless we are heavily invested in FOSS, we work for a company that is trying to bring in revenue to support payroll.  I am not saying that FOSS does not bring in revenue, but I would say many of the most successful FOSS projects are funded through the generosity of the community and businesses which leverage their technology.  This means that any DevOps model that most of us are producing against is centered around some concept of value engineering.  Value engineering is a tough topic to cover holistically, but the general idea is that technology must support some kind of product, service, widget, etc. that brings value to the market.  </p>



<p>My experience is that the emphasis on value engineering is far too constraining to the internal consumers of your DevOps pipelines.  Sure, we work for a business that needs to make revenue to be successful, but; I believe that the idea of value engineering goes both into the market and inversely into the team producing the technology.  This article will touch more on the idealistic side of what DevOps can do for teams with the idea of ancillary market benefits being gained by a team doing DevOps well.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>
</div></div>



<div class="wp-container-9 wp-block-group"><div class="wp-block-group__inner-container">
<h2>Primary Considerations for DevOps Deployments</h2>



<div class="wp-container-2 wp-block-group"><div class="wp-block-group__inner-container">
<h3>Goals and Values</h3>


<div class="wp-block-image">
<figure class="alignright size-medium"><img src="https://www.valewood.org/cdn-cgi/image/width=300,height=197,fit=crop,quality=80,format=auto,onerror=redirect,metadata=none/wp-content/uploads/2022/08/annie-spratt-hCb3lIB8L8E-unsplash.jpg" alt="DevOps Team" class="wp-image-108"/></figure></div>


<p>This is probably one of the toughest considerations to grasp and do well.  Goals and values are closely aligned and intertwined yet it is very simple for them to shift directions very quickly.  A business is always going to have some kind of goal that they are trying to reach, and a technology team will also have goals and aspirations that they are reaching for as well.  Let&#8217;s all remember that as technologists, we got into this for the love of technology no matter how jaded we may have become by trying to accomplish a never-ending stream of difficult customer requirements.</p>



<p>Since DevOps is as much about the team as it is about the business, make sure that goals/values swing in both directions. There may be a business-related goal out there to reduce defects by X% or increase the speed of delivery of a feature by Y timeline, but those goals are only part of the story.  As technologists, we owe each other an awesome experience developing and delivering technology.  Make sure the team takes time to learn and understand each other in a constructive way, and set goals through understanding each other values.</p>
</div></div>



<div class="wp-container-3 wp-block-group"><div class="wp-block-group__inner-container">
<h3>Approachability</h3>



<p>A DevOps pipeline should be approachable to the consumers of the pipeline.  Not only should a team be able to use it, but a team should also be able to enhance it.  Generally, this is boiled down to technology choice, but I believe that is the second facet of approachability.  A group must first determine what activities their pipelines should be responsible for.  Some tools are good at certain parts of pipeline development and some are not, and by determining the activities; a team can make good technology choices that support the rest of the considerations below. </p>



<p>To illustrate this point, here is an example of what I mean by approachability.  The gold standard for a complete DevOps pipeline is one that allows you to commit code and it is safely delivered to production.  Starting a journey at its finale is rarely a good idea.  That means a group must determine their jumping-off point which will usually lead a team into some kind of configuration management.  Ensuring 100% of configurations are stored in a code repository can be an extremely daunting task simply due to the vast array of methods and technologies available to accomplish that goal.  Start small by getting the team involved in adding and pushing configuration management.  Listen to the concerns of the team and work your way toward addressing those concerns.  Ensure that the team around you are bought into your ideas and methods.  Do not be afraid to pivot based on feedback to ensure that your methods are well received before moving on to the next phase which may be orchestration, testing, monitoring, etc.</p>



<p>If the team is struggling to get going with DevOps, I would encourage them to read through <a href="https://www.valewood.org/practicing-devops/" data-type="post" data-id="14" target="_blank" rel="noopener">Practicing DevOps – A Surprising Alternative</a> which may give them some interesting insights on how to get engaged.</p>
</div></div>



<div class="wp-container-4 wp-block-group"><div class="wp-block-group__inner-container">
<h3>Repeatability and Dependability</h3>



<p>When designing a pipeline, a focus should be on how DevOps can help with the repeatability of known tasks and how dependably can automation take hold to accomplish tasks which used to be in the domain of mere mortals.  This is often harder to quantify than you may think.  Let&#8217;s take something as simple as adding metadata to a build that ties back to a commit hash.  In Golang you will be using an <code>-ldflags</code> param to a <code>go build</code> command which must be able to run a git command to understand the hash of the head commit.  If your build environment has both Windows and Linux build agents, can both of them reliably run your command?</p>



<p>Another way to think about Dependability is to consider the end consumers of what you are DevOps-ing.  Do they expect your pipeline to fail safe or fail in an unsafe way?  As long as they can rely on specific failure scenarios, then they can at least depend on your pipeline doing the same thing.  If your pipeline is consistently failing in new and unforeseen ways, then the only thing that the teams around you can depend on is that your pipeline is unreliable.</p>
</div></div>



<div class="wp-container-5 wp-block-group"><div class="wp-block-group__inner-container">
<h3>Speed</h3>



<p>The first thing that a business will talk about is &#8220;Speed of Delivery&#8221;.  If we can ship more products/products faster, then the business will make more revenue.  Companies like <a href="https://www.github.com/" data-internallinksmanager029f6b8e52c="6" title="Github" rel="nofollow noopener" target="_blank">GitHub</a> and Amazon got it right by fully automating their deployments. In a post from 2012, GitHub was deploying roughly 200 times per day to production. Amazon deploys to production every 11.7 seconds equaling roughly ~7400 deployments per day. This speed to production ensures that code does not sit and languish in a code repository for days or worse, weeks.</p>



<p>Amazon and Github are actually ensuring updates are reaching other engineers and architects quickly reducing the overall feedback loop and increasing the opportunities for learning.  By ensuring that a higher number of smaller units are going to production either as minor improvements or feature-gated enhancements, the teams that are working on their products are able to shorten their feedback loop which pushes decision-making as close to the individual contributor as possible.  The more we can empower the people around us with information, the better we will all be and the faster rumor mills will be stopped dead in their tracks.</p>
</div></div>



<div class="wp-container-6 wp-block-group"><div class="wp-block-group__inner-container">
<h3>Flexibility</h3>



<p>More often than not, design choices have been made for you which you can not really walk back to ensure that all technology fits a specific pipeline or delivery flow model.  This is quite alright when you design with flexibility in mind.  In my experience, the general overall steps of a DevOps pipeline will always be the same.  I will cover those steps in a subsequent blog post.  If you take a step back and look at what you are producing and turn them into more of an interface-style design, then the only thing that is really changing is your concrete implementation of functionality.  That is the panacea of flexibility because only a portion of your overall work changes.  You are able to get an economy of scale out of other materials that team members owe each other like validations, documentation, expectation setting, etc.</p>
</div></div>



<div class="wp-container-7 wp-block-group"><div class="wp-block-group__inner-container">
<h3>Feedback Loops</h3>



<p>Getting feedback into the hands of stakeholders will help aid in good decision-making along with the overall stability of a solution.  The most important consideration here is this: make sure your feedback loops are consumable and actionable.  Spamming your stakeholders, business or technical, can create a TON of churn which doesn&#8217;t do anyone any good.  Ensure that any feedback provided is directly actionable.</p>



<p>Sometimes this is easier said than done.  Starting out, you will end up with a deluge of information that feels insurmountable.  The most dangerous thing you can do is either silence the information or assume that you are seeing false positives.  False positives can happen, and it is very much worth digging in and understanding why.  On the other hand, silencing information and subsequently ignoring it can lead to mishaps in the future.  Dive in and get to know your tooling and ensure you are doing everything you can to logically keep them clean.</p>
</div></div>



<div class="wp-container-8 wp-block-group"><div class="wp-block-group__inner-container">
<h3>Completeness</h3>



<p>An incomplete DevOps pipeline with some jank will inevitably lead to issues that erode confidence in the technology stack.  There is no gold standard of 100% complete here, but you can transpose completeness with confidence in most cases.  If your team and business partners feel that the pipeline is doing everything that it should, then you are in great shape.  If your pipeline feels like there is something left to be desired, don&#8217;t ignore that feeling and continue to build confidence through completeness.</p>
</div></div>
</div></div>



<div class="wp-container-11 wp-block-group"><div class="wp-block-group__inner-container">
<h2>Technology</h2>



<div class="wp-container-10 wp-block-group"><div class="wp-block-group__inner-container">
<h3>A GitOps Methodology</h3>



<p>First, I think we need to define what GitOps is.  GitOps is the idea that on a push to a repository, a full deployment pipeline can take place which deploys code into production.  On top of that, all controls, settings, adjustments, etc. happen from the Git repository rather than a smattering of distributed user interfaces.  This is a developer/technologist first approach which means that all changes will need to be visibly pushed to central source control before electricity is run through them out in the wild.</p>



<p>GitOps being a developer/technologist first approach is an important consideration to make because not everyone who is normally part of the technology delivery flow is necessarily a technology-minded individual contributor.  When making a change over to GitOps, you will need to consider what barrier to entry this creates for the end users and design your GitOps flow to be inclusive of all contributors, not just the contributors who are in the know.</p>
</div></div>



<h3>Tools</h3>


<div class="wp-block-image">
<figure class="alignleft size-medium"><img src="https://www.valewood.org/cdn-cgi/image/width=300,height=244,fit=crop,quality=80,format=auto,onerror=redirect,metadata=none/wp-content/uploads/2022/08/todd-quackenbush-IClZBVw5W5A-unsplash.jpg" alt="DevOps Tools" class="wp-image-235"/></figure></div>


<p>Selection of the right tools to do the job is both a critical juncture in any project and sparks the most religious debates showing where allegiances really lie.  Don&#8217;t fall into that trap.  A tool performs an action through specific syntax.  At it&#8217;s core, my preferred technology stack consists of something which orchestrates actions, something which performs tests, and something which performs configuration management.  This generally means <a href="https://www.ansible.com/" data-internallinksmanager029f6b8e52c="7" title="Ansible">Ansible</a>, Inspec, and <a href="https://www.chef.io/" data-internallinksmanager029f6b8e52c="8" title="Chef">Chef</a>/<a href="https://puppet.com/" data-internallinksmanager029f6b8e52c="9" title="Puppet">Puppet</a>.  Could you skip the Chef/Puppet and do everything 100% in ansible?  Absolutely.  Could you skip ansible and do everything in Chef/Puppet?  Absolutely!  I think the point is that anyone who argues that there is a right or wrong way to go about tool selection is flat-out wrong.  The tools must work for the team dynamic and then work for the technology.  If you start at technology first, more often than not, that effort will fail.</p>
</div></div>



<h2>Conclusion</h2>



<p>As you can see above, there are a lot of things to consider when putting together a DevOps pipeline, most of which have nothing to do with technology at all.  One of the best things I have learned in my time building and deploying DevOps pipelines is this: If the pipeline does not work for the people, then the pipeline does not work at all.  Consider how you are going to push on the soft skills side of your DevOps practices more than the technological side when starting out.  As you grow in your understanding of what DevOps really is technologically, you will come to appreciate that 90% of the problem is solved before the first line of code is ever put into a repository.</p>



<div class="wp-container-12 wp-block-group"><div class="wp-block-group__inner-container">
<h2>References</h2>



<ul><li><a href="https://icinga.com/blog/2022/05/25/embedding-git-commit-information-in-go-binaries/" target="_blank" rel="noreferrer noopener">Embedding Git Commit Information in Go Binaries</a></li></ul>
</div></div>
]]></content:encoded>
					
					<wfw:commentRss>https://www.valewood.org/devops-deployments-fast-easy-and-fun/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Practicing DevOps &#8211; A Surprising Alternative</title>
		<link>https://www.valewood.org/practicing-devops/</link>
					<comments>https://www.valewood.org/practicing-devops/#respond</comments>
		
		<dc:creator><![CDATA[Geoff Wagner]]></dc:creator>
		<pubDate>Sun, 07 Aug 2022 20:26:05 +0000</pubDate>
				<category><![CDATA[DevOps]]></category>
		<category><![CDATA[devops]]></category>
		<guid isPermaLink="false">/?p=14</guid>

					<description><![CDATA[A very common question that I see over on Reddit is &#8220;How do I do the DevOps?&#8221; or &#8220;How do I get better at DevOps?&#8221;. I think that this question fails to meet the fundamental understanding of what DevOps really&#8230;]]></description>
										<content:encoded><![CDATA[
<p>A very common question that I see over on Reddit is &#8220;How do I do the <a href="https://www.valewood.org/topics/devops/" data-internallinksmanager029f6b8e52c="15" title="Demystifying the DevOps Methodology and How You Can Leverage it for Success!​" target="_blank" rel="noopener">DevOps</a>?&#8221; or &#8220;How do I get better at DevOps?&#8221;.  I think that this question fails to meet the fundamental understanding of what DevOps really is.</p>



<p>On its face; DevOps blogs, articles, YouTube videos, etc. will classify DevOps as a series of tools that are composed to do some form of IaC or Configuration Management.  While this is a small component of DevOps, it is not the whole story.  DevOps is more about enabling the flow of delivery than it is about any singular or composition of tools.  Basic human nature will tell us that we always want to get more for less, and DevOps is the &#8220;branding&#8221; behind that idea in technology.  I have more to come on this topic down below.  With this basic understanding, I want to get into the meat of the issue first.</p>


<p>
<ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-7120242057450442"
     data-ad-slot="6094810801"></ins>
</p>



<h2 style="font-style:normal;font-weight:700">The Good, The Bad, and The Jaded</h2>



<p>The responses to this question are always interesting.  The most common responses come from the husks of talented yet jaded idealists who have had every ounce of their positivity sucked out by their corporate overlords&#8230; or maybe they don&#8217;t get enough hugs on a regular basis.  Either way, I believe that this makes it difficult for someone to break into a space that interests them.  So, let&#8217;s look at some versions of what DevOps is first, and then let&#8217;s talk about how you can practice it!</p>



<p>DevOps ensures that the flow of value (generally custom software) is enhanced to be faster, more reliable, and continuously deployable.  Knowing that the technology space is a vast expanse with a nearly infinite number of ways to accomplish this, what can an aspiring DevOps engineer do to break into this space?  I think the simplest answer is to do your research on delivery patterns more than specific technologies.</p>



<p>Technology delivery is done by humans with preconceived ideas about what is or is not important when it comes to things like quality delivery.  This means that there is no single &#8220;Best&#8221; or &#8220;Right&#8221; way to do DevOps.  Any technology which is put in place must work for the people who are consuming it.  Think about it like front-end design on a website.  I personally don&#8217;t really care for flashy front-end designs which are loaded to the hilt with highly stylized graphics.  I enjoy a much cleaner and minimalist aesthetic.  This means that I am going to gravitate toward websites that present that aesthetic to me and I will generally abandon a website that does not.  You can think about how you accomplish a DevOps flow in exactly the same way.  Something which is overly complex with too many rules or considerations may not play well with the consumers of your pipeline where it may be just what the doctor ordered with other teams.  This is why understanding and researching delivery patterns is so important to start with.</p>



<p>The next step I would take is to identify a use case that you are passionate about.  Spend some time looking at a variety of tooling which can help take that use case and put it into a CI/CD stance.  Something like <a href="https://pages.github.com/" data-internallinksmanager029f6b8e52c="11" title="Github Pages" rel="nofollow noopener" target="_blank">GitHub pages</a> is a really good starting point.  Make yourself a generic website talking about yourself and your skills.  This will help us understand the fundamental flow of releasing a piece of software out into the wild.  From there, start looking at adding page stats to your Github Pages profile which requires calculation in a build pipeline.  Add tests, add SCSS/SASS compilation, push some images to cloud storage and link them in, etc.  All of these steps help illustrate the complexity of flow at an extremely minimal cost if not free depending on what kinds of complexity you want to add.  </p>



<p>Once you have all of that in place, think about what you are doing from a market competitiveness standpoint and take a hard pivot.  Maybe this is replacing your site&#8217;s themes or layouts.  Maybe this is moving from Github pages to <a href="https://www.digitalocean.com/" data-internallinksmanager029f6b8e52c="5" title="DigialOcean" rel="nofollow noopener" target="_blank">DigitalOcean</a> running on a server using configuration management.  This could also be containerizing your pipeline into a <a href="https://kubernetes.io/" data-internallinksmanager029f6b8e52c="4" title="Kubernetes" rel="nofollow noopener" target="_blank">Kubernetes</a> deployment.  Any/all of these activities are what businesses do all of the time to stay relevant in the market.  By understanding what is an important inflow of delivery, you can lean out your pipelines and ensure that they work well for the pivot you are looking to make.  </p>



<p>Lastly,  don&#8217;t be afraid to get a peer review from someone.  Because DevOps is about flow, assume that your way of thinking about a problem is NOT the best way to approach it.  By getting a peer review you are getting a more global view of what is or is not important to potential consumers of your delivery flow.  Their feedback may be around adding features, reducing complexity, or pointers to more standard ways to approach a problem.  All of that is good and should not be taken personally.</p>



<h2>Flow of delivery</h2>



<p>So, what is flow of delivery?  Flow of delivery is the idea that you should be able to quantify all of the steps from the second a task is started through the time that thing is released for consumption by the market.  In software, this generally means: The time it takes from when <a href="https://www.imdb.com/title/tt0151804/characters/nm0726223" target="_blank" rel="noreferrer noopener">Tom Smykowski</a> receives a request to the time in which it is available to the customer.</p>



<p>In the antiquated world of slow monolithic SDLC practices, you could have any number of double-digit touchpoints all leading to a monolithic release of software going out for consumption.  Each of those touch points continues to increase the cost and reduce the agility of the specific work product being produced.  This is unavoidable if you are not interested in optimizing that SDLC process.</p>



<p>In a DevOps delivery model, Tom should be able to bring in a request which is then broken down into smaller continuously deployable units which are able to make it to production once committed.  This generally leads to a shift in overall spending from individual touchpoints over to automated testing.  Customers can get their value much sooner by having smaller portions of their solution delivered to them in real time.  They are also able to provide feedback which makes the inevitable pivot much more achievable.</p>



<p>What I believe is generally missed when making this calculated decision of a change from monolithic SDLC over to DevOps is simply this: Saying you want DevOps doesn&#8217;t work when the team that is delivering your product does not work in lock step with the same goals to accomplish DevOps.  If DevOps was a single-faceted practice, then it would be called Dev or Ops, not DevOps.  The automation, principles, technology, and processes must work for the team which is delivering the solution.  There is NO &#8220;one size fits all&#8221; solution for DevOps.  As leaders, we must enable people to do well and people will often astound us.  If we expect technology to make people better, then we failed before we started.</p>



<h2>So, Is DevOps Easy to Learn?</h2>



<p>This question implies that there is a potential mastery of DevOps.  I believe that the idea of DevOps is evolving and changing rapidly which does make it a bit of a moving target.  You can compartmentalize DevOps into some small chunks like building a simple release pipeline which does make DevOps very easy to learn. </p>



<p>I also believe that DevOps takes a mindset shift from focusing on getting a task done to focusing on getting something released.  The better you can get at breaking work down into chunks, accomplishing working through those chunks, and quickly getting them released to receive feedback and criticisms all of which ladders up to meeting a high standard of quality; the better handle you are getting on DevOps.  If you are focused on answering the question &#8220;how does technology X do a thing&#8221;, there is room for that but, your DevOps journey is going to take a bit longer.  </p>



<p>If you start to expand even further into aspects like the vast array of tools that the <a href="https://www.cncf.io/" data-internallinksmanager029f6b8e52c="12" title="CNCF" rel="nofollow noopener" target="_blank">CNCF</a> has to offer, then you are going to be learning and growing for a very long time.  I believe that the simplest jumping-off point on a DevOps journey is to build some simple deployment pipelines from something like GitHub and GitHub Pages or <a href="https://pages.cloudflare.com/" data-internallinksmanager029f6b8e52c="10" title="Cloudflare Pages" rel="nofollow noopener" target="_blank">CloudFlare Pages</a> utilizing some scripting and git-flow to get used to the nuances that are required when diving more fully into DevOps.</p>



<h2>Conclusion</h2>



<p>How do you practice DevOps?  First, read about traditional SDLC flows and read about DevOps flows.  Understand the differences and why the market must modernize to stay competitive.  Next, get interested in enabling the flow of technology delivery and practice delivering your own technology in some simple use cases.  Last, get some peer reviews to help grow your global perspective.</p>



<h3>Additional Resources</h3>



<p>Below are some additional resources which help understand the fundamentals of an SLDC and automated delivery:</p>



<ul><li><a href="https://hackr.io/blog/sdlc-methodologies" target="_blank" rel="noreferrer noopener">https://hackr.io/blog/sdlc-methodologies</a></li><li><a href="https://developerexperience.io/practices/automated-deployment" target="_blank" rel="noreferrer noopener">https://developerexperience.io/practices/automated-deployment</a></li><li><a href="https://www.redhat.com/en/topics/automation/what-is-deployment-automation" target="_blank" rel="noreferrer noopener">https://www.redhat.com/en/topics/automation/what-is-deployment-automation</a></li><li><a href="https://aws.amazon.com/builders-library/automating-safe-hands-off-deployments/" target="_blank" rel="noreferrer noopener">https://aws.amazon.com/builders-library/automating-safe-hands-off-deployments/</a></li></ul>
]]></content:encoded>
					
					<wfw:commentRss>https://www.valewood.org/practicing-devops/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
